{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frequent-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(rc={'figure.figsize':(1.33*11.7,1.33*8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "false-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdirs(rootdir, dirs):\n",
    "    #https://www.techiedelight.com/list-all-subdirectories-in-directory-python/\n",
    "    for file in os.listdir(rootdir):\n",
    "        d = os.path.join(rootdir, file)\n",
    "        if os.path.isdir(d):\n",
    "            dirs.append(d+'/')\n",
    "            #print(d)\n",
    "            listdirs(d, dirs)\n",
    "    return dirs\n",
    "rootdir = '../logfiles/'\n",
    "dirs = []\n",
    "dirs = listdirs(rootdir, dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effective-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    '../logfiles/baseline/',\n",
    "    '../logfiles/experiments/re_pruning/',\n",
    "    '../logfiles/experiments/gd_top_k_mc_ac_dk/',\n",
    "    \n",
    "    '../logfiles/ablation_study/alexnet_mixed/',\n",
    "    '../logfiles/ablation_study/resnet_mixed/',\n",
    "    \n",
    "    '../logfiles/ablation_study/admm_intra/',\n",
    "    '../logfiles/ablation_study/admm_retrain/',\n",
    "    \n",
    "    '../logfiles/ablation_study/gd_top_k/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_intra/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_retrain/',\n",
    "    \n",
    "    '../logfiles/ablation_study/re_pruning/',\n",
    "    '../logfiles/ablation_study/re_pruning_admm_retrain/',\n",
    "    '../logfiles/ablation_study/re_pruning_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac_admm_retrain/',\n",
    "    '../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_retrain/'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premier-footwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logfiles/ablation_study/\n",
      "../logfiles/ablation_study/admm_intra/\n",
      "../logfiles/ablation_study/admm_retrain/\n",
      "../logfiles/ablation_study/alexnet_mixed/\n",
      "../logfiles/ablation_study/gd_top_k/\n",
      "../logfiles/ablation_study/gd_top_k_mc/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_intra/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_retrain/\n",
      "../logfiles/ablation_study/resnet_mixed/\n",
      "../logfiles/ablation_study/re_pruning/\n",
      "../logfiles/ablation_study/re_pruning_ac/\n",
      "../logfiles/ablation_study/re_pruning_ac_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_ac_admm_retrain/\n",
      "../logfiles/ablation_study/re_pruning_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_admm_retrain/\n",
      "../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_retrain/\n",
      "../logfiles/baseline/\n",
      "../logfiles/experiments/\n",
      "../logfiles/experiments/gd_top_k_mc_ac_dk/\n",
      "../logfiles/experiments/re_pruning/\n",
      "../logfiles/experiments/re_pruning_ac/\n",
      "../logfiles/experiments/re_pruning_gd_top_k_mc_ac_dk_admm_intra/\n"
     ]
    }
   ],
   "source": [
    "paths = dirs\n",
    "logs = []\n",
    "for path in paths:\n",
    "    print(path, flush=True)\n",
    "    fnames = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for fname in fnames:\n",
    "        if 'json' in fname:\n",
    "            with open(path+fname, 'r') as f:\n",
    "                logs.append(json.load(f))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greek-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_eval(dataset, model, name, specs_to_print, results_to_print, plt_corr = True):\n",
    "    pd_dict = {}\n",
    "    for log in logs:\n",
    "        if (log['METADATA']['EXPERIMENT']['dataset'] == dataset and \n",
    "            log['METADATA']['EXPERIMENT']['name'] == name and\n",
    "            log['METADATA']['EXPERIMENT']['model'] == model):\n",
    "            #if log['LOGDATA']['test_accuracy'][-1] <= 0.1:\n",
    "            #    continue\n",
    "            outstring = model.upper() + ' ' + dataset.upper() + ' ' + name.upper() + '\\n'\n",
    "            for key in specs_to_print:\n",
    "                section = None\n",
    "                if key in log['METADATA']['SPECIFICATION']:\n",
    "                    section = 'SPECIFICATION'\n",
    "                if key in log['METADATA']['EXPERIMENT']:\n",
    "                    section = 'EXPERIMENT'\n",
    "                \n",
    "                outstring += key + ':' + log['METADATA'][section][key] + '\\n'\n",
    "                if key not in pd_dict:\n",
    "                    pd_dict[key] = []\n",
    "                pd_dict[key].append(float(log['METADATA'][section][key]))\n",
    "            #outstring += '\\n'\n",
    "            for key in results_to_print:\n",
    "                if type(log['LOGDATA'][key]) == type([]):\n",
    "                    outstring += key + ':' + str(round(log['LOGDATA'][key][-1], 2)) + '\\n'\n",
    "                    if key not in pd_dict:\n",
    "                        pd_dict[key] = []\n",
    "                    pd_dict[key].append(log['LOGDATA'][key][-1])\n",
    "                else:\n",
    "                    outstring += key + ':' + str(round(log['LOGDATA'][key], 2)) + '\\n'\n",
    "                    if key not in pd_dict:\n",
    "                        pd_dict[key] = []\n",
    "                    pd_dict[key].append(log['LOGDATA'][key])\n",
    "                    \n",
    "            #    if type(log['LOGDATA'][key]) == type([]):\n",
    "            #        plt.plot(log['LOGDATA'][key], label=key)\n",
    "            #plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "            #plt.legend()\n",
    "            #plt.show()\n",
    "            outstring+='\\n'\n",
    "            print(outstring)\n",
    "                \n",
    "    if plt_corr:\n",
    "        pd_df = pd.DataFrame(pd_dict)\n",
    "        if len(pd_df) > 0:\n",
    "            pd_df = pd_df.loc[:, (pd_df != pd_df.iloc[0]).any()] #drop const cols\n",
    "            sns.heatmap(pd_df.corr(), cbar=True, annot=True, cmap='RdBu')\n",
    "            plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "            plt.xticks(rotation=45) \n",
    "            plt.show()\n",
    "            \n",
    "def cross_eval(best_results, datasets, models, name, specs_to_print, results_to_print, plt_corr = True):\n",
    "    pd_dict = {}\n",
    "    res_dict = {}\n",
    "    best_config = {}\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            if model not in res_dict:\n",
    "                res_dict[model] = {}\n",
    "            if dataset not in res_dict[model]:\n",
    "                res_dict[model][dataset] = {}\n",
    "            if model not in best_config:\n",
    "                best_config[model] = {}\n",
    "            if dataset not in best_config[model]:\n",
    "                best_config[model][dataset] = {}\n",
    "            res_dict[model][dataset]['test_accuracy'] = 0.0\n",
    "            res_dict[model][dataset]['total_su'] = 1.0\n",
    "            res_dict[model][dataset]['current_su_fwd'] = 1.0\n",
    "            res_dict[model][dataset]['current_sparsity'] = 0.0\n",
    "            \n",
    "            for log in logs:\n",
    "                if (log['METADATA']['EXPERIMENT']['dataset'] == dataset and \n",
    "                    log['METADATA']['EXPERIMENT']['name'] == name and\n",
    "                    log['METADATA']['EXPERIMENT']['model'] == model):\n",
    "                    outstring = model.upper() + ' ' + dataset.upper() + ' ' + name.upper() + '\\n'\n",
    "                    if log['LOGDATA']['test_accuracy'][-1] <= 0.1:\n",
    "                        continue\n",
    "                    if log['LOGDATA']['test_accuracy'][-1] > 1:\n",
    "                        log['LOGDATA']['test_accuracy'] = [x * 1e-2 for x in log['LOGDATA']['test_accuracy']]\n",
    "                        \n",
    "                    #TODO = selectable . in rounding\n",
    "                    if round(res_dict[model][dataset]['test_accuracy'],2) < round(log['LOGDATA']['test_accuracy'][-1],2):\n",
    "                        res_dict[model][dataset]['test_accuracy'] = log['LOGDATA']['test_accuracy'][-1]\n",
    "                        if name != 'baseline':\n",
    "                            res_dict[model][dataset]['current_su_fwd'] = log['LOGDATA']['current_su_fwd'][-1]\n",
    "                            res_dict[model][dataset]['total_su'] = log['LOGDATA']['total_su'][-1]\n",
    "                            res_dict[model][dataset]['current_sparsity'] = log['LOGDATA']['current_sparsity'][-1]\n",
    "                            best_config[model][dataset]['METADATA'] = log['METADATA']\n",
    "                    if round(res_dict[model][dataset]['test_accuracy'],2) == round(log['LOGDATA']['test_accuracy'][-1],2):\n",
    "                        if name != 'baseline':\n",
    "                            if round(res_dict[model][dataset]['total_su'],2) < round(log['LOGDATA']['total_su'][-1],2):\n",
    "                                res_dict[model][dataset]['current_su_fwd'] = log['LOGDATA']['current_su_fwd'][-1]\n",
    "                                res_dict[model][dataset]['test_accuracy'] = log['LOGDATA']['test_accuracy'][-1]\n",
    "                                res_dict[model][dataset]['total_su'] = log['LOGDATA']['total_su'][-1]\n",
    "                                res_dict[model][dataset]['current_sparsity'] = log['LOGDATA']['current_sparsity'][-1]\n",
    "                                best_config[model][dataset]['METADATA'] = log['METADATA']\n",
    "                    \n",
    "                    for key in specs_to_print:\n",
    "                        section = None\n",
    "                        if key in log['METADATA']['SPECIFICATION']:\n",
    "                            section = 'SPECIFICATION'\n",
    "                        if key in log['METADATA']['EXPERIMENT']:\n",
    "                            section = 'EXPERIMENT'\n",
    "\n",
    "                        outstring += key + ':' + log['METADATA'][section][key] + '\\n'\n",
    "                        if key not in pd_dict:\n",
    "                            pd_dict[key] = []\n",
    "                        pd_dict[key].append(float(log['METADATA'][section][key]))\n",
    "                    #outstring += '\\n'\n",
    "                    for key in results_to_print:\n",
    "                        if type(log['LOGDATA'][key]) == type([]):\n",
    "                            outstring += key + ':' + str(round(log['LOGDATA'][key][-1], 2)) + '\\n'\n",
    "                            if key not in pd_dict:\n",
    "                                pd_dict[key] = []\n",
    "                            pd_dict[key].append(log['LOGDATA'][key][-1])\n",
    "                        else:\n",
    "                            outstring += key + ':' + str(round(log['LOGDATA'][key], 2)) + '\\n'\n",
    "                            if key not in pd_dict:\n",
    "                                pd_dict[key] = []\n",
    "                            pd_dict[key].append(log['LOGDATA'][key])\n",
    "\n",
    "                    #    if type(log['LOGDATA'][key]) == type([]):\n",
    "                    #        plt.plot(log['LOGDATA'][key], label=key)\n",
    "                    #plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "                    #plt.legend()\n",
    "                    #plt.show()\n",
    "                    outstring+='\\n'\n",
    "                    #print(outstring)\n",
    "    for model in res_dict:\n",
    "        for dataset in res_dict[model]:\n",
    "            if res_dict[model][dataset]['test_accuracy'] > 0.0:\n",
    "                #print(res_dict[model][dataset].keys())\n",
    "                print('EXP.: {}, MODEL: {}, DATA: {}'.format(name, model, dataset))\n",
    "                print('ACC.: {}, TRAIN SU: {}, INF. SU: {}, SP.: {}'.format(\n",
    "                      round(res_dict[model][dataset]['test_accuracy'],2),\n",
    "                      round(res_dict[model][dataset]['total_su'],2),\n",
    "                      round(res_dict[model][dataset]['current_su_fwd'],2),\n",
    "                      round(res_dict[model][dataset]['current_sparsity'],2)))\n",
    "                #print(best_config[model][dataset])\n",
    "    print('\\n\\n')\n",
    "    if plt_corr:\n",
    "        pd_df = pd.DataFrame(pd_dict)\n",
    "        if len(pd_df) > 0:\n",
    "            pd_df = pd_df.loc[:, (pd_df != pd_df.iloc[0]).any()] #drop const cols\n",
    "            sns.heatmap(pd_df.corr(), cbar=True, annot=True, cmap='RdBu')\n",
    "            plt.title(name.upper())\n",
    "            plt.xticks(rotation=90) \n",
    "            plt.show()\n",
    "            \n",
    "    best_results[name] = {'cfg' : best_config, 'res': res_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "engaged-choice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: baseline, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: resnet18, DATA: cifar100\n",
      "ACC.: 0.43, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: resnet20, DATA: cifar10\n",
      "ACC.: 0.8, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: resnet32, DATA: cifar10\n",
      "ACC.: 0.81, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: resnet32, DATA: cifar100\n",
      "ACC.: 0.47, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: resnet50, DATA: cifar10\n",
      "ACC.: 0.74, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.74, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: alexnet_s, DATA: cifar100\n",
      "ACC.: 0.41, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: mobilenet_v2, DATA: cifar10\n",
      "ACC.: 0.77, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: mobilenet_v2, DATA: cifar100\n",
      "ACC.: 0.43, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: mobilenet_v3_s, DATA: cifar10\n",
      "ACC.: 0.69, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: mobilenet_v3_s, DATA: cifar100\n",
      "ACC.: 0.38, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg8, DATA: cifar10\n",
      "ACC.: 0.77, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg8, DATA: cifar100\n",
      "ACC.: 0.46, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg11, DATA: cifar10\n",
      "ACC.: 0.76, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg11, DATA: cifar100\n",
      "ACC.: 0.36, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg13, DATA: cifar10\n",
      "ACC.: 0.76, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg13, DATA: cifar100\n",
      "ACC.: 0.28, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg16, DATA: cifar10\n",
      "ACC.: 0.72, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: baseline, MODEL: vgg16, DATA: cifar100\n",
      "ACC.: 0.26, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n",
      "EXP.: admm_intra, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 2.48, INF. SU: 1.86, SP.: 0.71\n",
      "EXP.: admm_intra, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.72, TRAIN SU: 2.17, INF. SU: 1.86, SP.: 0.98\n",
      "EXP.: admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.03, INF. SU: 12.01, SP.: 0.99\n",
      "\n",
      "\n",
      "\n",
      "EXP.: admm_retrain, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.7, TRAIN SU: 1.32, INF. SU: 1.86, SP.: 0.71\n",
      "EXP.: admm_retrain, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.7, TRAIN SU: 1.53, INF. SU: 1.86, SP.: 0.98\n",
      "EXP.: admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 1.24, INF. SU: 12.01, SP.: 0.99\n",
      "\n",
      "\n",
      "\n",
      "EXP.: gd_top_k, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.76, TRAIN SU: 1.24, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.73, TRAIN SU: 1.48, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.07, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n",
      "EXP.: gd_top_k_mc, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.77, TRAIN SU: 1.1, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.72, TRAIN SU: 1.47, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 1.73, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n",
      "EXP.: gd_top_k_mc_ac, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.77, TRAIN SU: 1.51, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.71, TRAIN SU: 1.83, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.32, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.77, TRAIN SU: 1.46, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: resnet18, DATA: cifar100\n",
      "ACC.: 0.42, TRAIN SU: 1.41, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.73, TRAIN SU: 1.5, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: alexnet_s, DATA: cifar100\n",
      "ACC.: 0.37, TRAIN SU: 1.51, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.21, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: mobilenet_v2, DATA: cifar10\n",
      "ACC.: 0.7, TRAIN SU: 1.42, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: mobilenet_v2, DATA: cifar100\n",
      "ACC.: 0.32, TRAIN SU: 1.41, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: mobilenet_v3_s, DATA: cifar10\n",
      "ACC.: 0.61, TRAIN SU: 1.37, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: mobilenet_v3_s, DATA: cifar100\n",
      "ACC.: 0.29, TRAIN SU: 1.36, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg8, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 1.52, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg8, DATA: cifar100\n",
      "ACC.: 0.39, TRAIN SU: 1.45, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg11, DATA: cifar10\n",
      "ACC.: 0.76, TRAIN SU: 1.48, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg11, DATA: cifar100\n",
      "ACC.: 0.35, TRAIN SU: 1.44, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg13, DATA: cifar10\n",
      "ACC.: 0.77, TRAIN SU: 1.46, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg13, DATA: cifar100\n",
      "ACC.: 0.38, TRAIN SU: 1.44, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg16, DATA: cifar10\n",
      "ACC.: 0.8, TRAIN SU: 1.42, INF. SU: 1.0, SP.: 0.0\n",
      "EXP.: gd_top_k_mc_ac_dk, MODEL: vgg16, DATA: cifar100\n",
      "ACC.: 0.37, TRAIN SU: 1.45, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n",
      "EXP.: gd_top_k_mc_ac_dk_admm_intra, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 3.01, INF. SU: 1.86, SP.: 0.71\n",
      "EXP.: gd_top_k_mc_ac_dk_admm_intra, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.73, TRAIN SU: 2.69, INF. SU: 1.86, SP.: 0.98\n",
      "EXP.: gd_top_k_mc_ac_dk_admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 3.44, INF. SU: 3.28, SP.: 0.94\n",
      "\n",
      "\n",
      "\n",
      "EXP.: gd_top_k_mc_ac_dk_admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.34, INF. SU: 12.01, SP.: 0.99\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.76, TRAIN SU: 1.22, INF. SU: 1.27, SP.: 0.96\n",
      "EXP.: re_pruning, MODEL: resnet18, DATA: cifar100\n",
      "ACC.: 0.42, TRAIN SU: 1.16, INF. SU: 1.19, SP.: 0.9\n",
      "EXP.: re_pruning, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.69, TRAIN SU: 1.27, INF. SU: 1.33, SP.: 0.42\n",
      "EXP.: re_pruning, MODEL: alexnet_s, DATA: cifar100\n",
      "ACC.: 0.34, TRAIN SU: 1.35, INF. SU: 1.37, SP.: 0.24\n",
      "EXP.: re_pruning, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 4.69, INF. SU: 4.05, SP.: 0.14\n",
      "EXP.: re_pruning, MODEL: mobilenet_v2, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 1.19, INF. SU: 1.29, SP.: 0.79\n",
      "EXP.: re_pruning, MODEL: mobilenet_v2, DATA: cifar100\n",
      "ACC.: 0.36, TRAIN SU: 1.08, INF. SU: 1.09, SP.: 0.53\n",
      "EXP.: re_pruning, MODEL: vgg8, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 1.23, INF. SU: 1.36, SP.: 0.91\n",
      "EXP.: re_pruning, MODEL: vgg11, DATA: cifar10\n",
      "ACC.: 0.7, TRAIN SU: 1.35, INF. SU: 1.41, SP.: 0.3\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning_ac, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 1.55, INF. SU: 1.2, SP.: 0.92\n",
      "EXP.: re_pruning_ac, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.67, TRAIN SU: 1.89, INF. SU: 1.39, SP.: 0.2\n",
      "EXP.: re_pruning_ac, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.98, TRAIN SU: 31.33, INF. SU: 14.29, SP.: 0.99\n",
      "EXP.: re_pruning_ac, MODEL: vgg8, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 1.62, INF. SU: 1.3, SP.: 0.91\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning_admm_intra, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 2.45, INF. SU: 1.92, SP.: 0.9\n",
      "EXP.: re_pruning_admm_intra, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.7, TRAIN SU: 2.58, INF. SU: 1.86, SP.: 0.99\n",
      "EXP.: re_pruning_admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 13.7, INF. SU: 12.02, SP.: 0.99\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning_admm_retrain, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.7, TRAIN SU: 1.37, INF. SU: 1.91, SP.: 0.88\n",
      "EXP.: re_pruning_admm_retrain, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.68, TRAIN SU: 2.27, INF. SU: 1.87, SP.: 0.99\n",
      "EXP.: re_pruning_admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.98, TRAIN SU: 13.83, INF. SU: 14.42, SP.: 0.99\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning_ac_admm_intra, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.75, TRAIN SU: 3.24, INF. SU: 1.9, SP.: 0.88\n",
      "EXP.: re_pruning_ac_admm_intra, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.71, TRAIN SU: 2.77, INF. SU: 1.86, SP.: 0.98\n",
      "EXP.: re_pruning_ac_admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 11.77, INF. SU: 12.03, SP.: 0.99\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning_ac_admm_retrain, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.67, TRAIN SU: 1.83, INF. SU: 1.9, SP.: 0.87\n",
      "EXP.: re_pruning_ac_admm_retrain, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.66, TRAIN SU: 2.53, INF. SU: 1.87, SP.: 0.99\n",
      "EXP.: re_pruning_ac_admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 9.66, INF. SU: 12.02, SP.: 0.99\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_intra, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.73, TRAIN SU: 3.2, INF. SU: 1.97, SP.: 0.91\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_intra, MODEL: resnet20, DATA: cifar10\n",
      "ACC.: 0.73, TRAIN SU: 3.09, INF. SU: 1.9, SP.: 0.79\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_intra, MODEL: resnet50, DATA: cifar10\n",
      "ACC.: 0.71, TRAIN SU: 3.35, INF. SU: 1.92, SP.: 0.81\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_intra, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.71, TRAIN SU: 2.87, INF. SU: 1.86, SP.: 0.98\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 17.86, INF. SU: 12.09, SP.: 0.99\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_intra, MODEL: mobilenet_v2, DATA: cifar10\n",
      "ACC.: 0.69, TRAIN SU: 2.08, INF. SU: 1.45, SP.: 0.46\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_intra, MODEL: mobilenet_v3_s, DATA: cifar10\n",
      "ACC.: 0.61, TRAIN SU: 1.97, INF. SU: 1.43, SP.: 0.48\n",
      "\n",
      "\n",
      "\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_retrain, MODEL: resnet18, DATA: cifar10\n",
      "ACC.: 0.7, TRAIN SU: 2.0, INF. SU: 1.98, SP.: 0.91\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_retrain, MODEL: alexnet_s, DATA: cifar10\n",
      "ACC.: 0.71, TRAIN SU: 3.25, INF. SU: 1.87, SP.: 0.99\n",
      "EXP.: re_pruning_gd_top_k_mc_ac_dk_admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 4.63, INF. SU: 12.05, SP.: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    'cifar10', \n",
    "    'cifar100', \n",
    "    'mnist',\n",
    "    'imagenet_tiny',\n",
    "    'imagenet_full',\n",
    "]\n",
    "models = [\n",
    "    'resnet18', \n",
    "    'resnet20',\n",
    "    'resnet32',\n",
    "    'resnet34',\n",
    "    'resnet50',\n",
    "    'alexnet_s', \n",
    "    'alexnet',\n",
    "    'lenet', \n",
    "    'mobilenet_v2', \n",
    "    'mobilenet_v3_s', \n",
    "    'vgg8',\n",
    "    'vgg11', \n",
    "    'vgg13', \n",
    "    'vgg16'\n",
    "         ]\n",
    "best_results = {}\n",
    "plt_corr = False\n",
    "sns.set(rc={'figure.figsize':(1.33*11.7,1.33*8.27)})\n",
    "\n",
    "cross_eval(best_results, datasets, models, 'baseline', ['lr', 'epochs', 'train_batch_size'], ['test_accuracy'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 'admm_intra', \n",
    "     ['lr', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'admm_retrain', \n",
    "     ['lr', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k', ['lr', 'k', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc', ['lr', 'k', 'se', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac_dk', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac_dk_admm_intra', \n",
    "     ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac_dk_admm_retrain',  \n",
    "     ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_ac', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', 'ac', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'repeat',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_ac_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', 'repeat',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_ac_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning_gd_top_k_mc_ac_dk_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "      'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "      'magnitude_t_l', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "      'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning_gd_top_k_mc_ac_dk_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "      'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "      'magnitude_t_l', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "      'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], plt_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_n, search_m, search_d = 're_pruning', 'mobilenet_v2', 'cifar10'\n",
    "for name in best_results:\n",
    "    if name == search_n:\n",
    "        for model in best_results[name]['cfg']:\n",
    "            if search_m == model:\n",
    "                for data in best_results[name]['cfg'][model]:\n",
    "                    if search_d == data:\n",
    "                        if 'METADATA' in best_results[name]['cfg'][model][data]:\n",
    "                            print(best_results[name]['cfg'][model][data]['METADATA'])\n",
    "        #print(best_results[name]['cfg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "necessary-niagara",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100+gd_top_k_mc_ac_dk+mobilenet_v2\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.32 0.0 0.0 0.0 0.29 0.0\n",
      "\n",
      "\n",
      "cifar10+gd_top_k_mc_ac_dk+mobilenet_v2\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.7 0.0 0.0 0.0 0.3 0.0\n",
      "\n",
      "\n",
      "cifar100+gd_top_k_mc_ac_dk+mobilenet_v3_s\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.29 0.0 0.0 0.0 0.26 0.04\n",
      "\n",
      "\n",
      "cifar10+gd_top_k_mc_ac_dk+mobilenet_v3_s\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.61 0.0 0.0 0.0 0.27 0.03\n",
      "\n",
      "\n",
      "cifar100+re_pruning+mobilenet_v2\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.36 0.54 0.53 0.08 0.08 0.01\n",
      "\n",
      "\n",
      "cifar10+re_pruning+mobilenet_v2\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.75 0.79 0.79 0.23 0.16 0.01\n",
      "0.44 0.5 0.5 0.08 0.07 0.25\n",
      "\n",
      "\n",
      "cifar10+re_pruning_gd_top_k_mc_ac_dk_admm_intra+mobilenet_v2\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.62 0.68 0.68 0.46 0.61 0.68\n",
      "0.67 0.45 0.45 0.31 0.52 0.56\n",
      "0.69 0.46 0.46 0.31 0.52 0.57\n",
      "\n",
      "\n",
      "cifar10+re_pruning_gd_top_k_mc_ac_dk_admm_intra+mobilenet_v3_s\n",
      "Acc, C/F, P, FLOPs(i), FLOPs(T), G\n",
      "0.61 0.53 0.48 0.3 0.49 0.53\n",
      "0.59 0.52 0.47 0.3 0.48 0.54\n",
      "0.59 0.51 0.47 0.3 0.45 0.42\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_logdict = {}\n",
    "for log in logs:\n",
    "    for key in log['LOGDATA']:\n",
    "        new_key = log['METADATA']['EXPERIMENT']['dataset'] + '+'\n",
    "        new_key += log['METADATA']['EXPERIMENT']['name'] + '+'\n",
    "        new_key += log['METADATA']['EXPERIMENT']['model']\n",
    "        if log['LOGDATA']['test_accuracy'][-1] <= 0.1:\n",
    "                continue\n",
    "        if new_key not in new_logdict:\n",
    "            new_logdict[new_key] = {}\n",
    "        if key not in new_logdict[new_key]:\n",
    "            new_logdict[new_key][key] = []\n",
    "            \n",
    "        if 'overhead' in key:\n",
    "            #print(sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]), flush=True)\n",
    "            if ('_mc' in log['METADATA']['EXPERIMENT']['name'] and\n",
    "                'gd' in log['METADATA']['EXPERIMENT']['name'] and not\n",
    "                'admm' in log['METADATA']['EXPERIMENT']['name']):\n",
    "                \n",
    "                    idx = int((len(log['LOGDATA'][key])*\n",
    "                           float(log['METADATA']['SPECIFICATION']['se'])/\n",
    "                           float(log['METADATA']['SPECIFICATION']['epochs'])))+1\n",
    "                    new_logdict[new_key][key].append(sum(log['LOGDATA'][key][:idx])/len(log['LOGDATA'][key]))\n",
    "                    #print(log['METADATA']['EXPERIMENT']['name'], \n",
    "                    #      sum(log['LOGDATA'][key][:idx])/len(log['LOGDATA'][key]),\n",
    "                    #      sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]))\n",
    "            else:\n",
    "                new_logdict[new_key][key].append(sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]))\n",
    "        elif 'gradient' in key:\n",
    "            new_logdict[new_key][key].append(sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]))\n",
    "        else:\n",
    "            new_logdict[new_key][key].append(log['LOGDATA'][key][-1])\n",
    "        \n",
    "n = 15\n",
    "for key in new_logdict:\n",
    "    if not 'baseline' in key and '+mob' in key:#('+resnet' in key or '+alexnet' in key or '+lenet' in key):\n",
    "        print(key)\n",
    "        idx = sorted(range(len(new_logdict[key]['total_su'])), \n",
    "                     key=lambda i: new_logdict[key]['total_su'][i])[-n:]\n",
    "        idx = idx[:3]\n",
    "        idx.reverse()\n",
    "        print('Acc, C/F, P, FLOPs(i), FLOPs(T), G')\n",
    "        for i in idx:\n",
    "            #print(new_logdict[key].keys()) #current_channel_sparsity', 'current_linear_sparsity #current_relative_overhead'\n",
    "            print(round(new_logdict[key]['test_accuracy'][i],2), \n",
    "                  round(new_logdict[key]['current_channel_sparsity'][i],2),\n",
    "                  round(new_logdict[key]['current_sparsity'][i],2),\n",
    "                  round(1-1/new_logdict[key]['current_su_fwd'][i],2),\n",
    "                  round(1-1/new_logdict[key]['total_su'][i],2),\n",
    "                  round(new_logdict[key]['current_gradient_sparsity'][i],2),\n",
    "                  #round(new_logdict[key]['current_relative_overhead'][i]*1e5, 2),\n",
    "                  #round(1-1/new_logdict[key]['current_su_bwd'][i],2),\n",
    "                  #round(new_logdict[key]['total_su'][i],2),\n",
    "                  #round(new_logdict[key]['current_sparsity'][i],2))+\n",
    "                  )\n",
    "                  #round(new_logdict[key]['current_relative_overhead'][i],2))\n",
    "        print('\\n')\n",
    "    #for subkey in new_logdict[key]:\n",
    "    #    if not 'features' in subkey and not 'weight' in subkey:\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-envelope",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'cifar10', \n",
    "    'cifar100', \n",
    "    'mnist',\n",
    "    'imagenet'\n",
    "]\n",
    "models = [\n",
    "    'resnet18', \n",
    "    'alexnet_s', \n",
    "    'lenet', \n",
    "    'mobilenet_v2', \n",
    "    'mobilenet_v3', \n",
    "    'vgg8',\n",
    "    'vgg11', \n",
    "    'vgg13', \n",
    "    'vgg16'\n",
    "         ]\n",
    "plt_corr = False\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'baseline', ['lr', 'epochs', 'train_batch_size'], ['test_accuracy'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'admm_intra', \n",
    "             ['lr', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'admm_retrain', \n",
    "             ['lr', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'gd_top_k', ['lr', 'k', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc', ['lr', 'k', 'se', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk_admm_intra', \n",
    "             ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk_admm_retrain',  \n",
    "             ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', 'ac', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'repeat',\n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', 'repeat',\n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning_gd_top_k_mc_ac_dk_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "              'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "              'magnitude_t_l', 'l1', 'l2', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "              'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-cookie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
