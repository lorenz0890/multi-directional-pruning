{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frequent-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "premier-footwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logfiles/baseline/\n",
      "../logfiles/experiments/re_pruning/\n",
      "../logfiles/experiments/gd_top_k_mc_ac_dk/\n",
      "../logfiles/ablation_study/alexnet_mixed/\n",
      "../logfiles/ablation_study/resnet_mixed/\n",
      "../logfiles/ablation_study/admm_intra/\n",
      "../logfiles/ablation_study/admm_retrain/\n",
      "../logfiles/ablation_study/gd_top_k/\n",
      "../logfiles/ablation_study/gd_top_k_mc/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_intra/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_retrain/\n",
      "../logfiles/ablation_study/re_pruning/\n",
      "../logfiles/ablation_study/re_pruning_admm_retrain/\n",
      "../logfiles/ablation_study/re_pruning_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_ac/\n",
      "../logfiles/ablation_study/re_pruning_ac_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_ac_admm_retrain/\n",
      "../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_intra/\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    '../logfiles/baseline/',\n",
    "    '../logfiles/experiments/re_pruning/',\n",
    "    '../logfiles/experiments/gd_top_k_mc_ac_dk/',\n",
    "    \n",
    "    '../logfiles/ablation_study/alexnet_mixed/',\n",
    "    '../logfiles/ablation_study/resnet_mixed/',\n",
    "    \n",
    "    '../logfiles/ablation_study/admm_intra/',\n",
    "    '../logfiles/ablation_study/admm_retrain/',\n",
    "    \n",
    "    '../logfiles/ablation_study/gd_top_k/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_intra/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_retrain/',\n",
    "    \n",
    "    '../logfiles/ablation_study/re_pruning/',\n",
    "    '../logfiles/ablation_study/re_pruning_admm_retrain/',\n",
    "    '../logfiles/ablation_study/re_pruning_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac_admm_retrain/',\n",
    "    '../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_intra/'\n",
    "        ]\n",
    "logs = []\n",
    "for path in paths:\n",
    "    print(path, flush=True)\n",
    "    fnames = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for fname in fnames:\n",
    "        if 'json' in fname:\n",
    "            with open(path+fname, 'r') as f:\n",
    "                logs.append(json.load(f))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "greek-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_eval(dataset, model, name, specs_to_print, results_to_print, plt_corr = True):\n",
    "    pd_dict = {}\n",
    "    for log in logs:\n",
    "        if (log['METADATA']['EXPERIMENT']['dataset'] == dataset and \n",
    "            log['METADATA']['EXPERIMENT']['name'] == name and\n",
    "            log['METADATA']['EXPERIMENT']['model'] == model):\n",
    "            outstring = model.upper() + ' ' + dataset.upper() + ' ' + name.upper() + '\\n'\n",
    "            for key in specs_to_print:\n",
    "                section = None\n",
    "                if key in log['METADATA']['SPECIFICATION']:\n",
    "                    section = 'SPECIFICATION'\n",
    "                if key in log['METADATA']['EXPERIMENT']:\n",
    "                    section = 'EXPERIMENT'\n",
    "                \n",
    "                outstring += key + ':' + log['METADATA'][section][key] + '\\n'\n",
    "                if key not in pd_dict:\n",
    "                    pd_dict[key] = []\n",
    "                pd_dict[key].append(float(log['METADATA'][section][key]))\n",
    "            #outstring += '\\n'\n",
    "            for key in results_to_print:\n",
    "                if type(log['LOGDATA'][key]) == type([]):\n",
    "                    outstring += key + ':' + str(round(log['LOGDATA'][key][-1], 2)) + '\\n'\n",
    "                    if key not in pd_dict:\n",
    "                        pd_dict[key] = []\n",
    "                    pd_dict[key].append(log['LOGDATA'][key][-1])\n",
    "                else:\n",
    "                    outstring += key + ':' + str(round(log['LOGDATA'][key], 2)) + '\\n'\n",
    "                    if key not in pd_dict:\n",
    "                        pd_dict[key] = []\n",
    "                    pd_dict[key].append(log['LOGDATA'][key])\n",
    "                    \n",
    "            #    if type(log['LOGDATA'][key]) == type([]):\n",
    "            #        plt.plot(log['LOGDATA'][key], label=key)\n",
    "            #plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "            #plt.legend()\n",
    "            #plt.show()\n",
    "            outstring+='\\n'\n",
    "            print(outstring)\n",
    "                \n",
    "    if plt_corr:\n",
    "        pd_df = pd.DataFrame(pd_dict)\n",
    "        if len(pd_df) > 0:\n",
    "            pd_df = pd_df.loc[:, (pd_df != pd_df.iloc[0]).any()] #drop const cols\n",
    "            sns.heatmap(pd_df.corr(), cbar=True, annot=True, cmap='RdBu')\n",
    "            plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "            plt.xticks(rotation=45) \n",
    "            plt.show()\n",
    "            \n",
    "def cross_eval(datasets, models, name, specs_to_print, results_to_print, plt_corr = True):\n",
    "    pd_dict = {}\n",
    "    res_dict = {}\n",
    "    best_config = {}\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            if model not in res_dict:\n",
    "                res_dict[model] = {}\n",
    "            if dataset not in res_dict[model]:\n",
    "                res_dict[model][dataset] = {}\n",
    "            if model not in best_config:\n",
    "                best_config[model] = {}\n",
    "            if dataset not in best_config[model]:\n",
    "                best_config[model][dataset] = {}\n",
    "            res_dict[model][dataset]['test_accuracy'] = 0.0\n",
    "            res_dict[model][dataset]['total_su'] = 1.0\n",
    "            res_dict[model][dataset]['current_sparsity'] = 0.0\n",
    "            \n",
    "            for log in logs:\n",
    "                if (log['METADATA']['EXPERIMENT']['dataset'] == dataset and \n",
    "                    log['METADATA']['EXPERIMENT']['name'] == name and\n",
    "                    log['METADATA']['EXPERIMENT']['model'] == model):\n",
    "                    outstring = model.upper() + ' ' + dataset.upper() + ' ' + name.upper() + '\\n'\n",
    "                    \n",
    "                    if log['LOGDATA']['test_accuracy'][-1] > 1:\n",
    "                        log['LOGDATA']['test_accuracy'] = [x * 1e-2 for x in log['LOGDATA']['test_accuracy']]\n",
    "                        \n",
    "                    #TODO = selectable . in rounding\n",
    "                    if round(res_dict[model][dataset]['test_accuracy'],2) < round(log['LOGDATA']['test_accuracy'][-1],2):\n",
    "                        res_dict[model][dataset]['test_accuracy'] = log['LOGDATA']['test_accuracy'][-1]\n",
    "                        if name != 'baseline':\n",
    "                            res_dict[model][dataset]['total_su'] = log['LOGDATA']['total_su'][-1]\n",
    "                            res_dict[model][dataset]['current_sparsity'] = log['LOGDATA']['current_sparsity'][-1]\n",
    "                            best_config[model][dataset]['METADATA'] = log['METADATA']\n",
    "                    if round(res_dict[model][dataset]['test_accuracy'],2) == round(log['LOGDATA']['test_accuracy'][-1],2):\n",
    "                        if name != 'baseline':\n",
    "                            if round(res_dict[model][dataset]['total_su'],2) < round(log['LOGDATA']['total_su'][-1],2):\n",
    "                                res_dict[model][dataset]['test_accuracy'] = log['LOGDATA']['test_accuracy'][-1]\n",
    "                                res_dict[model][dataset]['total_su'] = log['LOGDATA']['total_su'][-1]\n",
    "                                res_dict[model][dataset]['current_sparsity'] = log['LOGDATA']['current_sparsity'][-1]\n",
    "                                best_config[model][dataset]['METADATA'] = log['METADATA']\n",
    "                    \n",
    "                    for key in specs_to_print:\n",
    "                        section = None\n",
    "                        if key in log['METADATA']['SPECIFICATION']:\n",
    "                            section = 'SPECIFICATION'\n",
    "                        if key in log['METADATA']['EXPERIMENT']:\n",
    "                            section = 'EXPERIMENT'\n",
    "\n",
    "                        outstring += key + ':' + log['METADATA'][section][key] + '\\n'\n",
    "                        if key not in pd_dict:\n",
    "                            pd_dict[key] = []\n",
    "                        pd_dict[key].append(float(log['METADATA'][section][key]))\n",
    "                    #outstring += '\\n'\n",
    "                    for key in results_to_print:\n",
    "                        if type(log['LOGDATA'][key]) == type([]):\n",
    "                            outstring += key + ':' + str(round(log['LOGDATA'][key][-1], 2)) + '\\n'\n",
    "                            if key not in pd_dict:\n",
    "                                pd_dict[key] = []\n",
    "                            pd_dict[key].append(log['LOGDATA'][key][-1])\n",
    "                        else:\n",
    "                            outstring += key + ':' + str(round(log['LOGDATA'][key], 2)) + '\\n'\n",
    "                            if key not in pd_dict:\n",
    "                                pd_dict[key] = []\n",
    "                            pd_dict[key].append(log['LOGDATA'][key])\n",
    "\n",
    "                    #    if type(log['LOGDATA'][key]) == type([]):\n",
    "                    #        plt.plot(log['LOGDATA'][key], label=key)\n",
    "                    #plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "                    #plt.legend()\n",
    "                    #plt.show()\n",
    "                    outstring+='\\n'\n",
    "                    #print(outstring)\n",
    "    for model in res_dict:\n",
    "        for dataset in res_dict[model]:\n",
    "            if res_dict[model][dataset]['test_accuracy'] > 0.0:\n",
    "                print(name, model, dataset,\n",
    "                      round(res_dict[model][dataset]['test_accuracy'],2),\n",
    "                      round(res_dict[model][dataset]['total_su'],2),\n",
    "                      round(res_dict[model][dataset]['current_sparsity'],2))\n",
    "                #print(best_config[model][dataset])\n",
    "    print('\\n\\n')\n",
    "    if plt_corr:\n",
    "        pd_df = pd.DataFrame(pd_dict)\n",
    "        if len(pd_df) > 0:\n",
    "            pd_df = pd_df.loc[:, (pd_df != pd_df.iloc[0]).any()] #drop const cols\n",
    "            sns.heatmap(pd_df.corr(), cbar=True, annot=True, cmap='RdBu')\n",
    "            plt.title(name.upper())\n",
    "            plt.xticks(rotation=90) \n",
    "            plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "engaged-choice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline resnet18 cifar10 0.75 1.0 0.0\n",
      "baseline resnet18 cifar100 0.43 1.0 0.0\n",
      "baseline alexnet_s cifar10 0.74 1.0 0.0\n",
      "baseline alexnet_s cifar100 0.41 1.0 0.0\n",
      "baseline lenet mnist 0.99 1.0 0.0\n",
      "baseline mobilenet_v2 cifar10 0.77 1.0 0.0\n",
      "baseline mobilenet_v2 cifar100 0.43 1.0 0.0\n",
      "baseline vgg8 cifar10 0.77 1.0 0.0\n",
      "baseline vgg8 cifar100 0.46 1.0 0.0\n",
      "baseline vgg11 cifar10 0.76 1.0 0.0\n",
      "baseline vgg11 cifar100 0.36 1.0 0.0\n",
      "baseline vgg13 cifar10 0.76 1.0 0.0\n",
      "baseline vgg13 cifar100 0.28 1.0 0.0\n",
      "baseline vgg16 cifar10 0.72 1.0 0.0\n",
      "baseline vgg16 cifar100 0.26 1.0 0.0\n",
      "\n",
      "\n",
      "\n",
      "admm_intra alexnet_s cifar10 0.72 2.17 0.98\n",
      "admm_intra lenet mnist 0.99 2.03 0.99\n",
      "\n",
      "\n",
      "\n",
      "admm_retrain alexnet_s cifar10 0.7 1.53 0.98\n",
      "admm_retrain lenet mnist 0.99 1.24 0.99\n",
      "\n",
      "\n",
      "\n",
      "gd_top_k resnet18 cifar10 0.76 1.11 0.0\n",
      "gd_top_k alexnet_s cifar10 0.73 1.48 0.0\n",
      "gd_top_k lenet mnist 0.99 2.07 0.0\n",
      "\n",
      "\n",
      "\n",
      "gd_top_k_mc resnet18 cifar10 0.77 1.1 0.0\n",
      "gd_top_k_mc alexnet_s cifar10 0.72 1.47 0.0\n",
      "gd_top_k_mc lenet mnist 0.99 1.73 0.0\n",
      "\n",
      "\n",
      "\n",
      "gd_top_k_mc_ac resnet18 cifar10 0.77 1.51 0.0\n",
      "gd_top_k_mc_ac alexnet_s cifar10 0.71 1.83 0.0\n",
      "gd_top_k_mc_ac lenet mnist 0.99 2.32 0.0\n",
      "\n",
      "\n",
      "\n",
      "gd_top_k_mc_ac_dk resnet18 cifar10 0.77 1.42 0.0\n",
      "gd_top_k_mc_ac_dk resnet18 cifar100 0.42 1.41 0.0\n",
      "gd_top_k_mc_ac_dk alexnet_s cifar10 0.73 1.5 0.0\n",
      "gd_top_k_mc_ac_dk alexnet_s cifar100 0.37 1.51 0.0\n",
      "gd_top_k_mc_ac_dk lenet mnist 0.99 2.21 0.0\n",
      "gd_top_k_mc_ac_dk mobilenet_v2 cifar10 0.7 1.42 0.0\n",
      "gd_top_k_mc_ac_dk mobilenet_v2 cifar100 0.32 1.41 0.0\n",
      "gd_top_k_mc_ac_dk vgg8 cifar10 0.75 1.52 0.0\n",
      "gd_top_k_mc_ac_dk vgg8 cifar100 0.39 1.45 0.0\n",
      "gd_top_k_mc_ac_dk vgg11 cifar10 0.76 1.48 0.0\n",
      "gd_top_k_mc_ac_dk vgg11 cifar100 0.35 1.44 0.0\n",
      "gd_top_k_mc_ac_dk vgg13 cifar10 0.77 1.46 0.0\n",
      "gd_top_k_mc_ac_dk vgg13 cifar100 0.38 1.44 0.0\n",
      "gd_top_k_mc_ac_dk vgg16 cifar10 0.8 1.42 0.0\n",
      "gd_top_k_mc_ac_dk vgg16 cifar100 0.37 1.45 0.0\n",
      "\n",
      "\n",
      "\n",
      "gd_top_k_mc_ac_dk_admm_intra resnet18 cifar10 0.1 1.79 0.0\n",
      "gd_top_k_mc_ac_dk_admm_intra alexnet_s cifar10 0.73 2.69 0.98\n",
      "gd_top_k_mc_ac_dk_admm_intra lenet mnist 0.99 3.44 0.94\n",
      "\n",
      "\n",
      "\n",
      "gd_top_k_mc_ac_dk_admm_retrain lenet mnist 0.99 2.34 0.99\n",
      "\n",
      "\n",
      "\n",
      "re_pruning resnet18 cifar10 0.76 1.22 0.96\n",
      "re_pruning resnet18 cifar100 0.42 1.16 0.9\n",
      "re_pruning alexnet_s cifar10 0.69 1.27 0.42\n",
      "re_pruning alexnet_s cifar100 0.34 1.35 0.24\n",
      "re_pruning lenet mnist 0.99 4.69 0.14\n",
      "re_pruning mobilenet_v2 cifar10 0.75 1.19 0.79\n",
      "re_pruning mobilenet_v2 cifar100 0.36 1.08 0.53\n",
      "re_pruning vgg8 cifar10 0.1 1.95 1.0\n",
      "re_pruning vgg8 cifar100 0.01 1.95 1.0\n",
      "re_pruning vgg11 cifar10 0.24 1.31 0.14\n",
      "re_pruning vgg11 cifar100 0.01 1.95 1.0\n",
      "re_pruning vgg13 cifar10 0.1 1.95 1.0\n",
      "re_pruning vgg13 cifar100 0.01 1.96 1.0\n",
      "re_pruning vgg16 cifar10 0.1 1.95 1.0\n",
      "re_pruning vgg16 cifar100 0.01 1.94 1.0\n",
      "\n",
      "\n",
      "\n",
      "re_pruning_ac resnet18 cifar10 0.75 1.55 0.92\n",
      "re_pruning_ac alexnet_s cifar10 0.67 1.89 0.2\n",
      "re_pruning_ac lenet mnist 0.98 31.33 0.99\n",
      "\n",
      "\n",
      "\n",
      "re_pruning_admm_intra alexnet_s cifar10 0.7 2.58 0.99\n",
      "re_pruning_admm_intra lenet mnist 0.99 13.7 0.99\n",
      "\n",
      "\n",
      "\n",
      "re_pruning_admm_retrain alexnet_s cifar10 0.68 2.27 0.99\n",
      "re_pruning_admm_retrain lenet mnist 0.98 13.83 0.99\n",
      "\n",
      "\n",
      "\n",
      "re_pruning_ac_admm_intra alexnet_s cifar10 0.69 2.82 0.98\n",
      "re_pruning_ac_admm_intra lenet mnist 0.99 11.77 0.99\n",
      "\n",
      "\n",
      "\n",
      "re_pruning_ac_admm_retrain alexnet_s cifar10 0.66 2.53 0.99\n",
      "re_pruning_ac_admm_retrain lenet mnist 0.99 9.66 0.99\n",
      "\n",
      "\n",
      "\n",
      "re_pruning_gd_top_k_mc_ac_dk_admm_intra lenet mnist 0.99 17.86 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    'cifar10', \n",
    "    'cifar100', \n",
    "    'mnist',\n",
    "    'imagenet_tiny',\n",
    "    'imagenet_full',\n",
    "]\n",
    "models = [\n",
    "    'resnet18', \n",
    "    'resnet_20',\n",
    "    'resnet_32',\n",
    "    'resnet_34',\n",
    "    'resnet_50',\n",
    "    'alexnet_s', \n",
    "    'alexnet',\n",
    "    'lenet', \n",
    "    'mobilenet_v2', \n",
    "    'mobilenet_v3', \n",
    "    'vgg8',\n",
    "    'vgg11', \n",
    "    'vgg13', \n",
    "    'vgg16'\n",
    "         ]\n",
    "plt_corr = False\n",
    "\n",
    "cross_eval(datasets, models, 'baseline', ['lr', 'epochs', 'train_batch_size'], ['test_accuracy'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(datasets, models, 'admm_intra', \n",
    "     ['lr', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 'admm_retrain', \n",
    "     ['lr', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "\n",
    "cross_eval(datasets, models, 'gd_top_k', ['lr', 'k', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 'gd_top_k_mc', ['lr', 'k', 'se', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 'gd_top_k_mc_ac', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 'gd_top_k_mc_ac_dk', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 'gd_top_k_mc_ac_dk_admm_intra', \n",
    "     ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 'gd_top_k_mc_ac_dk_admm_retrain',  \n",
    "     ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(datasets, models, 're_pruning', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 're_pruning_ac', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', 'ac', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(datasets, models, 're_pruning_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'repeat',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 're_pruning_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 're_pruning_ac_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', 'repeat',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(datasets, models, 're_pruning_ac_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "\n",
    "cross_eval(datasets, models, 're_pruning_gd_top_k_mc_ac_dk_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "      'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "      'magnitude_t_l', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "      'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "present-envelope",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG8 CIFAR10 BASELINE\n",
      "lr:1e-1\n",
      "epochs:100\n",
      "train_batch_size:256\n",
      "test_accuracy:0.77\n",
      "\n",
      "\n",
      "VGG8 CIFAR100 BASELINE\n",
      "lr:1e-1\n",
      "epochs:100\n",
      "train_batch_size:256\n",
      "test_accuracy:0.46\n",
      "\n",
      "\n",
      "VGG8 CIFAR10 GD_TOP_K_MC_AC_DK\n",
      "lr:1e-3\n",
      "k:3\n",
      "se:3\n",
      "ac:8\n",
      "train_batch_size:256\n",
      "test_accuracy:0.75\n",
      "total_su:1.52\n",
      "total_su_fwd:1.0\n",
      "total_su_bwd:2.05\n",
      "current_sparsity:0.0\n",
      "current_relative_overhead:0.0\n",
      "\n",
      "\n",
      "VGG8 CIFAR100 GD_TOP_K_MC_AC_DK\n",
      "lr:1e-3\n",
      "k:3\n",
      "se:3\n",
      "ac:8\n",
      "train_batch_size:256\n",
      "test_accuracy:0.39\n",
      "total_su:1.45\n",
      "total_su_fwd:1.0\n",
      "total_su_bwd:1.87\n",
      "current_sparsity:0.0\n",
      "current_relative_overhead:0.0\n",
      "\n",
      "\n",
      "VGG8 CIFAR10 RE_PRUNING\n",
      "lr:1e-1\n",
      "prune_epochs:2\n",
      "metric_q_l:0.001\n",
      "metric_q_c:0.05\n",
      "scale_l:0.25\n",
      "scale_c:0.25\n",
      "sample_l:100\n",
      "sample_c:100\n",
      "softness_l:0.9\n",
      "softness_c:0.9\n",
      "magnitude_t_c:1e-3\n",
      "magnitude_t_l:1e-3\n",
      "l1:1e-4\n",
      "l2:1e-8\n",
      "train_batch_size:256\n",
      "test_accuracy:0.1\n",
      "total_su:1.29\n",
      "total_su_fwd:1.25\n",
      "total_su_bwd:1.31\n",
      "current_sparsity:1.0\n",
      "current_relative_overhead:0.0\n",
      "\n",
      "\n",
      "VGG8 CIFAR10 RE_PRUNING\n",
      "lr:1e-1\n",
      "prune_epochs:2\n",
      "metric_q_l:0.001\n",
      "metric_q_c:0.05\n",
      "scale_l:0.25\n",
      "scale_c:0.25\n",
      "sample_l:100\n",
      "sample_c:100\n",
      "softness_l:0.9\n",
      "softness_c:0.9\n",
      "magnitude_t_c:1e-3\n",
      "magnitude_t_l:1e-3\n",
      "l1:1e-4\n",
      "l2:1e-8\n",
      "train_batch_size:256\n",
      "test_accuracy:0.1\n",
      "total_su:1.95\n",
      "total_su_fwd:1.94\n",
      "total_su_bwd:1.95\n",
      "current_sparsity:1.0\n",
      "current_relative_overhead:0.0\n",
      "\n",
      "\n",
      "VGG8 CIFAR100 RE_PRUNING\n",
      "lr:1e-1\n",
      "prune_epochs:2\n",
      "metric_q_l:0.001\n",
      "metric_q_c:0.05\n",
      "scale_l:0.25\n",
      "scale_c:0.25\n",
      "sample_l:100\n",
      "sample_c:100\n",
      "softness_l:0.9\n",
      "softness_c:0.9\n",
      "magnitude_t_c:1e-3\n",
      "magnitude_t_l:1e-3\n",
      "l1:1e-4\n",
      "l2:1e-8\n",
      "train_batch_size:256\n",
      "test_accuracy:0.01\n",
      "total_su:1.95\n",
      "total_su_fwd:1.94\n",
      "total_su_bwd:1.95\n",
      "current_sparsity:1.0\n",
      "current_relative_overhead:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    'cifar10', \n",
    "    'cifar100', \n",
    "    'mnist',\n",
    "    'imagenet'\n",
    "]\n",
    "models = [\n",
    "    #'resnet18', \n",
    "    #'alexnet_s', \n",
    "    #'lenet', \n",
    "    #'mobilenet_v2', \n",
    "    #'mobilenet_v3', \n",
    "    'vgg8',\n",
    "    #'vgg11', \n",
    "    #'vgg13', \n",
    "    #'vgg16'\n",
    "         ]\n",
    "plt_corr = False\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'baseline', ['lr', 'epochs', 'train_batch_size'], ['test_accuracy'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'admm_intra', \n",
    "             ['lr', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'admm_retrain', \n",
    "             ['lr', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'gd_top_k', ['lr', 'k', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc', ['lr', 'k', 'se', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk_admm_intra', \n",
    "             ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk_admm_retrain',  \n",
    "             ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', 'ac', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'repeat',\n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', 'repeat',\n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning_gd_top_k_mc_ac_dk_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "              'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "              'magnitude_t_l', 'l1', 'l2', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "              'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-occasion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
