{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frequent-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(rc={'figure.figsize':(1.33*11.7,1.33*8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effective-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    '../logfiles/baseline/',\n",
    "    '../logfiles/experiments/re_pruning/',\n",
    "    '../logfiles/experiments/gd_top_k_mc_ac_dk/',\n",
    "    \n",
    "    '../logfiles/ablation_study/alexnet_mixed/',\n",
    "    '../logfiles/ablation_study/resnet_mixed/',\n",
    "    \n",
    "    '../logfiles/ablation_study/admm_intra/',\n",
    "    '../logfiles/ablation_study/admm_retrain/',\n",
    "    \n",
    "    '../logfiles/ablation_study/gd_top_k/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_intra/',\n",
    "    '../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_retrain/',\n",
    "    \n",
    "    '../logfiles/ablation_study/re_pruning/',\n",
    "    '../logfiles/ablation_study/re_pruning_admm_retrain/',\n",
    "    '../logfiles/ablation_study/re_pruning_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_ac_admm_retrain/',\n",
    "    '../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_intra/',\n",
    "    '../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_retrain/'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "false-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdirs(rootdir, dirs):\n",
    "    #https://www.techiedelight.com/list-all-subdirectories-in-directory-python/\n",
    "    for file in os.listdir(rootdir):\n",
    "        d = os.path.join(rootdir, file)\n",
    "        if os.path.isdir(d):\n",
    "            dirs.append(d+'/')\n",
    "            #print(d)\n",
    "            listdirs(d, dirs)\n",
    "    return dirs\n",
    "rootdir = '../logfiles/'\n",
    "dirs = []\n",
    "dirs = listdirs(rootdir, dirs)\n",
    "dirs.append(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premier-footwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logfiles/ablation_study/\n",
      "../logfiles/ablation_study/admm_intra/\n",
      "../logfiles/ablation_study/admm_retrain/\n",
      "../logfiles/ablation_study/alexnet_mixed/\n",
      "../logfiles/ablation_study/gd_top_k/\n",
      "../logfiles/ablation_study/gd_top_k_mc/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_intra/\n",
      "../logfiles/ablation_study/gd_top_k_mc_ac_dk_admm_retrain/\n",
      "../logfiles/ablation_study/resnet_mixed/\n",
      "../logfiles/ablation_study/re_pruning/\n",
      "../logfiles/ablation_study/re_pruning_ac/\n",
      "../logfiles/ablation_study/re_pruning_ac_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_ac_admm_retrain/\n",
      "../logfiles/ablation_study/re_pruning_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_admm_retrain/\n",
      "../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_intra/\n",
      "../logfiles/ablation_study/re_pruning_gd_top_k_mc_ac_dk_admm_retrain/\n",
      "../logfiles/baseline/\n",
      "../logfiles/experiments/\n",
      "../logfiles/experiments/gd_top_k_mc_ac_dk/\n",
      "../logfiles/experiments/re_pruning/\n",
      "../logfiles/experiments/re_pruning_ac/\n",
      "../logfiles/experiments/re_pruning_gd_top_k_mc_ac_dk_admm_intra/\n",
      "../logfiles/\n"
     ]
    }
   ],
   "source": [
    "paths = dirs\n",
    "logs = []\n",
    "for path in paths:\n",
    "    print(path, flush=True)\n",
    "    fnames = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for fname in fnames:\n",
    "        #if 'vgg8' in fname:\n",
    "        #    print(fname)\n",
    "        if 'json' in fname:\n",
    "            with open(path+fname, 'r') as f:\n",
    "                logs.append(json.load(f))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greek-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_eval(dataset, model, name, specs_to_print, results_to_print, plt_corr = True):\n",
    "    pd_dict = {}\n",
    "    for log in logs:\n",
    "        if (log['METADATA']['EXPERIMENT']['dataset'] == dataset and \n",
    "            log['METADATA']['EXPERIMENT']['name'] == name and\n",
    "            log['METADATA']['EXPERIMENT']['model'] == model):\n",
    "            #if log['LOGDATA']['test_accuracy'][-1] <= 0.1:\n",
    "            #    continue\n",
    "            outstring = model.upper() + ' ' + dataset.upper() + ' ' + name.upper() + '\\n'\n",
    "            for key in specs_to_print:\n",
    "                section = None\n",
    "                if key in log['METADATA']['SPECIFICATION']:\n",
    "                    section = 'SPECIFICATION'\n",
    "                if key in log['METADATA']['EXPERIMENT']:\n",
    "                    section = 'EXPERIMENT'\n",
    "                \n",
    "                outstring += key + ':' + log['METADATA'][section][key] + '\\n'\n",
    "                if key not in pd_dict:\n",
    "                    pd_dict[key] = []\n",
    "                pd_dict[key].append(float(log['METADATA'][section][key]))\n",
    "            #outstring += '\\n'\n",
    "            for key in results_to_print:\n",
    "                if type(log['LOGDATA'][key]) == type([]):\n",
    "                    outstring += key + ':' + str(round(log['LOGDATA'][key][-1], 2)) + '\\n'\n",
    "                    if key not in pd_dict:\n",
    "                        pd_dict[key] = []\n",
    "                    pd_dict[key].append(log['LOGDATA'][key][-1])\n",
    "                else:\n",
    "                    outstring += key + ':' + str(round(log['LOGDATA'][key], 2)) + '\\n'\n",
    "                    if key not in pd_dict:\n",
    "                        pd_dict[key] = []\n",
    "                    pd_dict[key].append(log['LOGDATA'][key])\n",
    "                    \n",
    "            #    if type(log['LOGDATA'][key]) == type([]):\n",
    "            #        plt.plot(log['LOGDATA'][key], label=key)\n",
    "            #plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "            #plt.legend()\n",
    "            #plt.show()\n",
    "            outstring+='\\n'\n",
    "            print(outstring)\n",
    "                \n",
    "    if plt_corr:\n",
    "        pd_df = pd.DataFrame(pd_dict)\n",
    "        if len(pd_df) > 0:\n",
    "            pd_df = pd_df.loc[:, (pd_df != pd_df.iloc[0]).any()] #drop const cols\n",
    "            sns.heatmap(pd_df.corr(), cbar=True, annot=True, cmap='RdBu')\n",
    "            plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "            plt.xticks(rotation=45) \n",
    "            plt.show()\n",
    "            \n",
    "def cross_eval(best_results, datasets, models, name, specs_to_print, results_to_print, plt_corr = True):\n",
    "    pd_dict = {}\n",
    "    res_dict = {}\n",
    "    best_config = {}\n",
    "    prec = 2\n",
    "    \n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            if model not in res_dict:\n",
    "                res_dict[model] = {}\n",
    "            if dataset not in res_dict[model]:\n",
    "                res_dict[model][dataset] = {}\n",
    "            if model not in best_config:\n",
    "                best_config[model] = {}\n",
    "            if dataset not in best_config[model]:\n",
    "                best_config[model][dataset] = {}\n",
    "            res_dict[model][dataset]['test_accuracy'] = 0.0\n",
    "            res_dict[model][dataset]['total_su'] = 1.0\n",
    "            res_dict[model][dataset]['current_su_fwd'] = 1.0\n",
    "            res_dict[model][dataset]['current_sparsity'] = 0.0\n",
    "            \n",
    "            for log in logs:\n",
    "                if (log['METADATA']['EXPERIMENT']['dataset'] == dataset and \n",
    "                    log['METADATA']['EXPERIMENT']['name'] == name and\n",
    "                    log['METADATA']['EXPERIMENT']['model'] == model):\n",
    "                    outstring = model.upper() + ' ' + dataset.upper() + ' ' + name.upper() + '\\n'\n",
    "                    #if log['LOGDATA']['test_accuracy'][-1] <= 0.1:\n",
    "                    #    continue\n",
    "                    if log['LOGDATA']['test_accuracy'][-1] > 1:\n",
    "                        log['LOGDATA']['test_accuracy'] = [x * 1e-2 for x in log['LOGDATA']['test_accuracy']]\n",
    "                        \n",
    "                    #TODO = selectable . in rounding\n",
    "                    \n",
    "                    if round(res_dict[model][dataset]['test_accuracy'],prec) < round(log['LOGDATA']['test_accuracy'][-1],prec):\n",
    "                        res_dict[model][dataset]['test_accuracy'] = log['LOGDATA']['test_accuracy'][-1]\n",
    "                        if name != 'baseline':\n",
    "                            res_dict[model][dataset]['current_su_fwd'] = log['LOGDATA']['current_su_fwd'][-1]\n",
    "                            res_dict[model][dataset]['total_su'] = log['LOGDATA']['total_su'][-1]\n",
    "                            res_dict[model][dataset]['current_sparsity'] = log['LOGDATA']['current_sparsity'][-1]\n",
    "                            best_config[model][dataset]['METADATA'] = log['METADATA']\n",
    "                    if round(res_dict[model][dataset]['test_accuracy'],prec) == round(log['LOGDATA']['test_accuracy'][-1],prec):\n",
    "                        if name != 'baseline':\n",
    "                            if round(res_dict[model][dataset]['total_su'],prec) < round(log['LOGDATA']['total_su'][-1],prec):\n",
    "                                res_dict[model][dataset]['current_su_fwd'] = log['LOGDATA']['current_su_fwd'][-1]\n",
    "                                res_dict[model][dataset]['test_accuracy'] = log['LOGDATA']['test_accuracy'][-1]\n",
    "                                res_dict[model][dataset]['total_su'] = log['LOGDATA']['total_su'][-1]\n",
    "                                res_dict[model][dataset]['current_sparsity'] = log['LOGDATA']['current_sparsity'][-1]\n",
    "                                best_config[model][dataset]['METADATA'] = log['METADATA']\n",
    "                    \n",
    "                    for key in specs_to_print:\n",
    "                        section = None\n",
    "                        if key in log['METADATA']['SPECIFICATION']:\n",
    "                            section = 'SPECIFICATION'\n",
    "                        if key in log['METADATA']['EXPERIMENT']:\n",
    "                            section = 'EXPERIMENT'\n",
    "\n",
    "                        outstring += key + ':' + log['METADATA'][section][key] + '\\n'\n",
    "                        if key not in pd_dict:\n",
    "                            pd_dict[key] = []\n",
    "                        pd_dict[key].append(float(log['METADATA'][section][key]))\n",
    "                    #outstring += '\\n'\n",
    "                    for key in results_to_print:\n",
    "                        if type(log['LOGDATA'][key]) == type([]):\n",
    "                            outstring += key + ':' + str(round(log['LOGDATA'][key][-1], prec)) + '\\n'\n",
    "                            if key not in pd_dict:\n",
    "                                pd_dict[key] = []\n",
    "                            pd_dict[key].append(log['LOGDATA'][key][-1])\n",
    "                        else:\n",
    "                            outstring += key + ':' + str(round(log['LOGDATA'][key], prec)) + '\\n'\n",
    "                            if key not in pd_dict:\n",
    "                                pd_dict[key] = []\n",
    "                            pd_dict[key].append(log['LOGDATA'][key])\n",
    "\n",
    "                    #    if type(log['LOGDATA'][key]) == type([]):\n",
    "                    #        plt.plot(log['LOGDATA'][key], label=key)\n",
    "                    #plt.title(model.upper() + ' ' + dataset.upper() + ' ' + name.upper())\n",
    "                    #plt.legend()\n",
    "                    #plt.show()\n",
    "                    outstring+='\\n'\n",
    "                    #print(outstring)\n",
    "    for model in res_dict:\n",
    "        for dataset in res_dict[model]:\n",
    "            if res_dict[model][dataset]['test_accuracy'] > 0.0:\n",
    "                #print(res_dict[model][dataset].keys())\n",
    "                print('EXP.: {}, MODEL: {}, DATA: {}'.format(name, model, dataset))\n",
    "                print('ACC.: {}, TRAIN SU: {}, INF. SU: {}, SP.: {}'.format(\n",
    "                      round(res_dict[model][dataset]['test_accuracy'],prec),\n",
    "                      round(res_dict[model][dataset]['total_su'],prec),\n",
    "                      round(res_dict[model][dataset]['current_su_fwd'],prec),\n",
    "                      round(res_dict[model][dataset]['current_sparsity'],prec)))\n",
    "                #print(best_config[model][dataset])\n",
    "    print('\\n\\n')\n",
    "    if plt_corr:\n",
    "        pd_df = pd.DataFrame(pd_dict)\n",
    "        if len(pd_df) > 0:\n",
    "            '''\n",
    "            corr = pd_df.corr()\n",
    "            mask = np.zeros_like(corr, dtype=np.bool)\n",
    "            mask[np.triu_indices_from(mask)] = True\n",
    "            pd_df = pd_df.loc[:, (pd_df != pd_df.iloc[0]).any()] #drop const cols\n",
    "            sns.heatmap(corr, mask=mask, cbar=True, square=True, annot=True, cmap='RdBu')\n",
    "            plt.title(name.upper())\n",
    "            plt.xticks(rotation=90) \n",
    "            plt.show()\n",
    "            '''\n",
    "            #for key in pd_df:\n",
    "            #    pd_df.boxplot(column=key)\n",
    "            #    plt.show()\n",
    "            #pd_df.boxplot()\n",
    "            #print(pd_df.describe(), flush=True)\n",
    "            display(pd_df.describe())\n",
    "            pass\n",
    "            \n",
    "    best_results[name] = {'cfg' : best_config, 'res': res_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hired-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO visualize hyperparameter distributions\n",
    "#TODO correlate percentages ADMM as avaerages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "engaged-choice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: baseline, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 1.0, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.993650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.993525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.993650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.993775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.993900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr  epochs  train_batch_size  test_accuracy\n",
       "count  2.0     2.0               2.0       2.000000\n",
       "mean   0.1    10.0             256.0       0.993650\n",
       "std    0.0     0.0               0.0       0.000354\n",
       "min    0.1    10.0             256.0       0.993400\n",
       "25%    0.1    10.0             256.0       0.993525\n",
       "50%    0.1    10.0             256.0       0.993650\n",
       "75%    0.1    10.0             256.0       0.993775\n",
       "max    0.1    10.0             256.0       0.993900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.13, INF. SU: 12.01, SP.: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>pre_epochs</th>\n",
       "      <th>epochs</th>\n",
       "      <th>re_epochs</th>\n",
       "      <th>repeat</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.387097</td>\n",
       "      <td>1.387097</td>\n",
       "      <td>1.387097</td>\n",
       "      <td>2.419355</td>\n",
       "      <td>163.096774</td>\n",
       "      <td>0.989848</td>\n",
       "      <td>1.722696</td>\n",
       "      <td>1.451732</td>\n",
       "      <td>1.920139</td>\n",
       "      <td>0.949317</td>\n",
       "      <td>0.038920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.204248e-19</td>\n",
       "      <td>0.495138</td>\n",
       "      <td>0.495138</td>\n",
       "      <td>0.495138</td>\n",
       "      <td>0.501610</td>\n",
       "      <td>97.536098</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.219689</td>\n",
       "      <td>0.114819</td>\n",
       "      <td>0.356833</td>\n",
       "      <td>0.079452</td>\n",
       "      <td>0.037846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.981900</td>\n",
       "      <td>1.370012</td>\n",
       "      <td>1.262184</td>\n",
       "      <td>1.390325</td>\n",
       "      <td>0.701568</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>1.568072</td>\n",
       "      <td>1.362519</td>\n",
       "      <td>1.646363</td>\n",
       "      <td>0.949042</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>1.671245</td>\n",
       "      <td>1.465781</td>\n",
       "      <td>1.807260</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.024962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.991850</td>\n",
       "      <td>1.870736</td>\n",
       "      <td>1.526635</td>\n",
       "      <td>2.242672</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.065417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>2.131420</td>\n",
       "      <td>1.658899</td>\n",
       "      <td>2.598491</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.101839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lr  pre_epochs     epochs  re_epochs     repeat  \\\n",
       "count  3.100000e+01   31.000000  31.000000  31.000000  31.000000   \n",
       "mean   1.000000e-03    1.387097   1.387097   1.387097   2.419355   \n",
       "std    2.204248e-19    0.495138   0.495138   0.495138   0.501610   \n",
       "min    1.000000e-03    1.000000   1.000000   1.000000   2.000000   \n",
       "25%    1.000000e-03    1.000000   1.000000   1.000000   2.000000   \n",
       "50%    1.000000e-03    1.000000   1.000000   1.000000   2.000000   \n",
       "75%    1.000000e-03    2.000000   2.000000   2.000000   3.000000   \n",
       "max    1.000000e-03    2.000000   2.000000   2.000000   3.000000   \n",
       "\n",
       "       train_batch_size  test_accuracy   total_su  total_su_fwd  total_su_bwd  \\\n",
       "count         31.000000      31.000000  31.000000     31.000000     31.000000   \n",
       "mean         163.096774       0.989848   1.722696      1.451732      1.920139   \n",
       "std           97.536098       0.002750   0.219689      0.114819      0.356833   \n",
       "min           64.000000       0.981900   1.370012      1.262184      1.390325   \n",
       "25%           64.000000       0.987800   1.568072      1.362519      1.646363   \n",
       "50%          256.000000       0.990400   1.671245      1.465781      1.807260   \n",
       "75%          256.000000       0.991850   1.870736      1.526635      2.242672   \n",
       "max          256.000000       0.994100   2.131420      1.658899      2.598491   \n",
       "\n",
       "       current_sparsity  current_relative_overhead  \n",
       "count         31.000000                  31.000000  \n",
       "mean           0.949317                   0.038920  \n",
       "std            0.079452                   0.037846  \n",
       "min            0.701568                   0.002847  \n",
       "25%            0.949042                   0.007550  \n",
       "50%            0.985947                   0.024962  \n",
       "75%            0.985947                   0.065417  \n",
       "max            0.985947                   0.101839  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 1.8, INF. SU: 12.01, SP.: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>pre_epochs</th>\n",
       "      <th>epochs</th>\n",
       "      <th>re_epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>4.409091</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>151.272727</td>\n",
       "      <td>0.991773</td>\n",
       "      <td>1.369581</td>\n",
       "      <td>1.327132</td>\n",
       "      <td>1.392365</td>\n",
       "      <td>0.981900</td>\n",
       "      <td>0.050091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.219433e-19</td>\n",
       "      <td>2.423282</td>\n",
       "      <td>2.988072</td>\n",
       "      <td>2.091003</td>\n",
       "      <td>97.852261</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.192270</td>\n",
       "      <td>0.163022</td>\n",
       "      <td>0.209476</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.038347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.989700</td>\n",
       "      <td>1.201755</td>\n",
       "      <td>1.189529</td>\n",
       "      <td>1.207955</td>\n",
       "      <td>0.959141</td>\n",
       "      <td>0.004210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.990775</td>\n",
       "      <td>1.221166</td>\n",
       "      <td>1.207571</td>\n",
       "      <td>1.230057</td>\n",
       "      <td>0.983797</td>\n",
       "      <td>0.024935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.991950</td>\n",
       "      <td>1.238255</td>\n",
       "      <td>1.207571</td>\n",
       "      <td>1.254189</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.038189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.992650</td>\n",
       "      <td>1.455195</td>\n",
       "      <td>1.401513</td>\n",
       "      <td>1.490844</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.099875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.993700</td>\n",
       "      <td>1.800106</td>\n",
       "      <td>1.662755</td>\n",
       "      <td>1.877657</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.101347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lr  pre_epochs     epochs  re_epochs  train_batch_size  \\\n",
       "count  2.200000e+01   22.000000  22.000000  22.000000         22.000000   \n",
       "mean   1.000000e-03    4.409091   7.500000   4.090909        151.272727   \n",
       "std    2.219433e-19    2.423282   2.988072   2.091003         97.852261   \n",
       "min    1.000000e-03    3.000000   3.000000   3.000000         64.000000   \n",
       "25%    1.000000e-03    3.000000   6.000000   3.000000         64.000000   \n",
       "50%    1.000000e-03    3.000000  10.000000   3.000000         64.000000   \n",
       "75%    1.000000e-03    5.000000  10.000000   5.000000        256.000000   \n",
       "max    1.000000e-03   10.000000  10.000000  10.000000        256.000000   \n",
       "\n",
       "       test_accuracy   total_su  total_su_fwd  total_su_bwd  current_sparsity  \\\n",
       "count      22.000000  22.000000     22.000000     22.000000         22.000000   \n",
       "mean        0.991773   1.369581      1.327132      1.392365          0.981900   \n",
       "std         0.001087   0.192270      0.163022      0.209476          0.008230   \n",
       "min         0.989700   1.201755      1.189529      1.207955          0.959141   \n",
       "25%         0.990775   1.221166      1.207571      1.230057          0.983797   \n",
       "50%         0.991950   1.238255      1.207571      1.254189          0.985947   \n",
       "75%         0.992650   1.455195      1.401513      1.490844          0.985947   \n",
       "max         0.993700   1.800106      1.662755      1.877657          0.985947   \n",
       "\n",
       "       current_relative_overhead  \n",
       "count                  22.000000  \n",
       "mean                    0.050091  \n",
       "std                     0.038347  \n",
       "min                     0.004210  \n",
       "25%                     0.024935  \n",
       "50%                     0.038189  \n",
       "75%                     0.099875  \n",
       "max                     0.101347  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: gd_top_k, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.07, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>k</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>1.707067</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.984932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.264824e-19</td>\n",
       "      <td>0.984732</td>\n",
       "      <td>94.534265</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>0.372986</td>\n",
       "      <td>7.177563e-11</td>\n",
       "      <td>1.315722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>1.211814</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.355356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>1.241419</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.411841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.986350</td>\n",
       "      <td>1.833823</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.187171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.988900</td>\n",
       "      <td>2.051198</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.323762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.990900</td>\n",
       "      <td>2.073161</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.473619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lr          k  train_batch_size  test_accuracy   total_su  \\\n",
       "count  1.200000e+01  12.000000         12.000000      12.000000  12.000000   \n",
       "mean   1.000000e-03   2.333333        128.000000       0.691517   1.707067   \n",
       "std    2.264824e-19   0.984732         94.534265       0.438344   0.372986   \n",
       "min    1.000000e-03   1.000000         64.000000       0.098000   1.211814   \n",
       "25%    1.000000e-03   1.000000         64.000000       0.098000   1.241419   \n",
       "50%    1.000000e-03   3.000000         64.000000       0.986350   1.833823   \n",
       "75%    1.000000e-03   3.000000        256.000000       0.988900   2.051198   \n",
       "max    1.000000e-03   3.000000        256.000000       0.990900   2.073161   \n",
       "\n",
       "       total_su_fwd  total_su_bwd  current_sparsity  current_relative_overhead  \n",
       "count  1.200000e+01     12.000000              12.0                  12.000000  \n",
       "mean   1.000000e+00      2.984932               0.0                   0.003813  \n",
       "std    7.177563e-11      1.315722               0.0                   0.002012  \n",
       "min    1.000000e+00      1.355356               0.0                   0.001242  \n",
       "25%    1.000000e+00      1.411841               0.0                   0.002636  \n",
       "50%    1.000000e+00      3.187171               0.0                   0.003410  \n",
       "75%    1.000000e+00      4.323762               0.0                   0.004651  \n",
       "max    1.000000e+00      4.473619               0.0                   0.007813  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: gd_top_k_mc, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.06, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>k</th>\n",
       "      <th>se</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.690733</td>\n",
       "      <td>1.569743</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.426123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.264824e-19</td>\n",
       "      <td>0.984732</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>94.534265</td>\n",
       "      <td>0.437783</td>\n",
       "      <td>0.352069</td>\n",
       "      <td>1.333594e-11</td>\n",
       "      <td>1.044245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>1.070817</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.110125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>1.139493</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.224955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.986200</td>\n",
       "      <td>1.693044</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.590905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.990050</td>\n",
       "      <td>1.797027</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.993625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.990700</td>\n",
       "      <td>2.055838</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.354838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lr          k         se  train_batch_size  test_accuracy  \\\n",
       "count  1.200000e+01  12.000000  12.000000         12.000000      12.000000   \n",
       "mean   1.000000e-03   2.333333   2.666667        128.000000       0.690733   \n",
       "std    2.264824e-19   0.984732   0.492366         94.534265       0.437783   \n",
       "min    1.000000e-03   1.000000   2.000000         64.000000       0.098000   \n",
       "25%    1.000000e-03   1.000000   2.000000         64.000000       0.098000   \n",
       "50%    1.000000e-03   3.000000   3.000000         64.000000       0.986200   \n",
       "75%    1.000000e-03   3.000000   3.000000        256.000000       0.990050   \n",
       "max    1.000000e-03   3.000000   3.000000        256.000000       0.990700   \n",
       "\n",
       "        total_su  total_su_fwd  total_su_bwd  current_sparsity  \\\n",
       "count  12.000000  1.200000e+01     12.000000              12.0   \n",
       "mean    1.569743  1.000000e+00      2.426123               0.0   \n",
       "std     0.352069  1.333594e-11      1.044245               0.0   \n",
       "min     1.070817  1.000000e+00      1.110125               0.0   \n",
       "25%     1.139493  1.000000e+00      1.224955               0.0   \n",
       "50%     1.693044  1.000000e+00      2.590905               0.0   \n",
       "75%     1.797027  1.000000e+00      2.993625               0.0   \n",
       "max     2.055838  1.000000e+00      4.354838               0.0   \n",
       "\n",
       "       current_relative_overhead  \n",
       "count                  12.000000  \n",
       "mean                    0.004473  \n",
       "std                     0.002897  \n",
       "min                     0.002179  \n",
       "25%                     0.002318  \n",
       "50%                     0.003391  \n",
       "75%                     0.004829  \n",
       "max                     0.010292  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: gd_top_k_mc_ac, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.33, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>k</th>\n",
       "      <th>se</th>\n",
       "      <th>ac</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>112.00000</td>\n",
       "      <td>0.988619</td>\n",
       "      <td>2.221818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.802051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.966527</td>\n",
       "      <td>85.86501</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.090178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>0.985200</td>\n",
       "      <td>2.035482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.220724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>0.987450</td>\n",
       "      <td>2.178059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.310710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>2.256514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.071423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>112.00000</td>\n",
       "      <td>0.990050</td>\n",
       "      <td>2.280501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.339752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>256.00000</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>2.333686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.004769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lr     k    se         ac  train_batch_size  test_accuracy  \\\n",
       "count  16.000  16.0  16.0  16.000000          16.00000      16.000000   \n",
       "mean    0.001   3.0   3.0   6.500000         112.00000       0.988619   \n",
       "std     0.000   0.0   0.0   3.966527          85.86501       0.001842   \n",
       "min     0.001   3.0   3.0   2.000000          64.00000       0.985200   \n",
       "25%     0.001   3.0   3.0   3.500000          64.00000       0.987450   \n",
       "50%     0.001   3.0   3.0   6.000000          64.00000       0.988950   \n",
       "75%     0.001   3.0   3.0   9.000000         112.00000       0.990050   \n",
       "max     0.001   3.0   3.0  12.000000         256.00000       0.991000   \n",
       "\n",
       "        total_su  total_su_fwd  total_su_bwd  current_sparsity  \\\n",
       "count  16.000000          16.0     16.000000              16.0   \n",
       "mean    2.221818           1.0      5.802051               0.0   \n",
       "std     0.090178           0.0      0.848892               0.0   \n",
       "min     2.035482           1.0      4.220724               0.0   \n",
       "25%     2.178059           1.0      5.310710               0.0   \n",
       "50%     2.256514           1.0      6.071423               0.0   \n",
       "75%     2.280501           1.0      6.339752               0.0   \n",
       "max     2.333686           1.0      7.004769               0.0   \n",
       "\n",
       "       current_relative_overhead  \n",
       "count                  16.000000  \n",
       "mean                    0.007738  \n",
       "std                     0.003429  \n",
       "min                     0.002121  \n",
       "25%                     0.006381  \n",
       "50%                     0.008160  \n",
       "75%                     0.010355  \n",
       "max                     0.011683  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: gd_top_k_mc_ac_dk, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.21, INF. SU: 1.0, SP.: 0.0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>k</th>\n",
       "      <th>se</th>\n",
       "      <th>ac</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17.000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001</td>\n",
       "      <td>2.764706</td>\n",
       "      <td>2.764706</td>\n",
       "      <td>8.0</td>\n",
       "      <td>131.764706</td>\n",
       "      <td>0.96650</td>\n",
       "      <td>1.918469</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.268949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.091410</td>\n",
       "      <td>0.437237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.577699</td>\n",
       "      <td>0.07147</td>\n",
       "      <td>0.388331</td>\n",
       "      <td>8.124844e-10</td>\n",
       "      <td>2.301938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.69600</td>\n",
       "      <td>1.258558</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.445420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.98770</td>\n",
       "      <td>1.757525</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.829072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.98910</td>\n",
       "      <td>1.988371</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.931031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.99020</td>\n",
       "      <td>2.212975</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.623648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.99150</td>\n",
       "      <td>2.508275</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>10.201946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lr          k         se    ac  train_batch_size  test_accuracy  \\\n",
       "count  17.000  17.000000  17.000000  17.0         17.000000       17.00000   \n",
       "mean    0.001   2.764706   2.764706   8.0        131.764706        0.96650   \n",
       "std     0.000   1.091410   0.437237   0.0         94.577699        0.07147   \n",
       "min     0.001   1.000000   2.000000   8.0         64.000000        0.69600   \n",
       "25%     0.001   3.000000   3.000000   8.0         64.000000        0.98770   \n",
       "50%     0.001   3.000000   3.000000   8.0         64.000000        0.98910   \n",
       "75%     0.001   3.000000   3.000000   8.0        256.000000        0.99020   \n",
       "max     0.001   4.000000   3.000000   8.0        256.000000        0.99150   \n",
       "\n",
       "        total_su  total_su_fwd  total_su_bwd  current_sparsity  \\\n",
       "count  17.000000  1.700000e+01     17.000000              17.0   \n",
       "mean    1.918469  1.000000e+00      4.268949               0.0   \n",
       "std     0.388331  8.124844e-10      2.301938               0.0   \n",
       "min     1.258558  1.000000e+00      1.445420               0.0   \n",
       "25%     1.757525  1.000000e+00      2.829072               0.0   \n",
       "50%     1.988371  1.000000e+00      3.931031               0.0   \n",
       "75%     2.212975  1.000000e+00      5.623648               0.0   \n",
       "max     2.508275  1.000000e+00     10.201946               0.0   \n",
       "\n",
       "       current_relative_overhead  \n",
       "count                  17.000000  \n",
       "mean                    0.005237  \n",
       "std                     0.003353  \n",
       "min                     0.001131  \n",
       "25%                     0.002193  \n",
       "50%                     0.004571  \n",
       "75%                     0.008742  \n",
       "max                     0.011688  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: gd_top_k_mc_ac_dk_admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 4.27, INF. SU: 4.42, SP.: 0.83\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>k</th>\n",
       "      <th>se</th>\n",
       "      <th>ac</th>\n",
       "      <th>pre_epochs</th>\n",
       "      <th>epochs</th>\n",
       "      <th>re_epochs</th>\n",
       "      <th>repeat</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>146.285714</td>\n",
       "      <td>0.984557</td>\n",
       "      <td>3.453470</td>\n",
       "      <td>1.872160</td>\n",
       "      <td>6.229555</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.035163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.628317</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.635004</td>\n",
       "      <td>0.166327</td>\n",
       "      <td>2.250004</td>\n",
       "      <td>0.058303</td>\n",
       "      <td>0.028431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>2.881362</td>\n",
       "      <td>1.689750</td>\n",
       "      <td>4.278066</td>\n",
       "      <td>0.830688</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.981900</td>\n",
       "      <td>2.950951</td>\n",
       "      <td>1.755477</td>\n",
       "      <td>4.513933</td>\n",
       "      <td>0.963538</td>\n",
       "      <td>0.014209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>3.279859</td>\n",
       "      <td>1.804247</td>\n",
       "      <td>5.096503</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.031695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>3.858506</td>\n",
       "      <td>1.990099</td>\n",
       "      <td>7.863354</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.046375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.988700</td>\n",
       "      <td>4.394155</td>\n",
       "      <td>2.119972</td>\n",
       "      <td>9.477742</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.087291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr    k   se   ac  pre_epochs  epochs  re_epochs  repeat  \\\n",
       "count  7.000  7.0  7.0  7.0         7.0     7.0        7.0     7.0   \n",
       "mean   0.001  3.0  3.0  8.0         1.0     1.0        1.0     3.0   \n",
       "std    0.000  0.0  0.0  0.0         0.0     0.0        0.0     0.0   \n",
       "min    0.001  3.0  3.0  8.0         1.0     1.0        1.0     3.0   \n",
       "25%    0.001  3.0  3.0  8.0         1.0     1.0        1.0     3.0   \n",
       "50%    0.001  3.0  3.0  8.0         1.0     1.0        1.0     3.0   \n",
       "75%    0.001  3.0  3.0  8.0         1.0     1.0        1.0     3.0   \n",
       "max    0.001  3.0  3.0  8.0         1.0     1.0        1.0     3.0   \n",
       "\n",
       "       train_batch_size  test_accuracy  total_su  total_su_fwd  total_su_bwd  \\\n",
       "count          7.000000       7.000000  7.000000      7.000000      7.000000   \n",
       "mean         146.285714       0.984557  3.453470      1.872160      6.229555   \n",
       "std          102.628317       0.004515  0.635004      0.166327      2.250004   \n",
       "min           64.000000       0.978000  2.881362      1.689750      4.278066   \n",
       "25%           64.000000       0.981900  2.950951      1.755477      4.513933   \n",
       "50%           64.000000       0.986600  3.279859      1.804247      5.096503   \n",
       "75%          256.000000       0.987400  3.858506      1.990099      7.863354   \n",
       "max          256.000000       0.988700  4.394155      2.119972      9.477742   \n",
       "\n",
       "       current_sparsity  current_relative_overhead  \n",
       "count          7.000000                   7.000000  \n",
       "mean           0.957364                   0.035163  \n",
       "std            0.058303                   0.028431  \n",
       "min            0.830688                   0.005989  \n",
       "25%            0.963538                   0.014209  \n",
       "50%            0.985947                   0.031695  \n",
       "75%            0.985947                   0.046375  \n",
       "max            0.985947                   0.087291  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: gd_top_k_mc_ac_dk_admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 2.89, INF. SU: 4.16, SP.: 0.92\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>k</th>\n",
       "      <th>se</th>\n",
       "      <th>ac</th>\n",
       "      <th>pre_epochs</th>\n",
       "      <th>epochs</th>\n",
       "      <th>re_epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.974883</td>\n",
       "      <td>2.329637</td>\n",
       "      <td>1.217308</td>\n",
       "      <td>4.860839</td>\n",
       "      <td>0.976017</td>\n",
       "      <td>0.065514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.264824e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.534265</td>\n",
       "      <td>0.024987</td>\n",
       "      <td>0.332491</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>2.440573</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.041812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.906500</td>\n",
       "      <td>1.774110</td>\n",
       "      <td>1.179107</td>\n",
       "      <td>2.287440</td>\n",
       "      <td>0.918026</td>\n",
       "      <td>0.006305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.978925</td>\n",
       "      <td>2.114851</td>\n",
       "      <td>1.224516</td>\n",
       "      <td>3.322865</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.026392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.984550</td>\n",
       "      <td>2.304161</td>\n",
       "      <td>1.224516</td>\n",
       "      <td>4.243915</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.076212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.988175</td>\n",
       "      <td>2.474343</td>\n",
       "      <td>1.224516</td>\n",
       "      <td>5.075883</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.092646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>2.887780</td>\n",
       "      <td>1.224516</td>\n",
       "      <td>10.484353</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.122770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lr     k    se    ac  pre_epochs  epochs  re_epochs  \\\n",
       "count  1.200000e+01  12.0  12.0  12.0        12.0    12.0       12.0   \n",
       "mean   1.000000e-03   3.0   3.0   8.0         2.0     6.0        2.0   \n",
       "std    2.264824e-19   0.0   0.0   0.0         0.0     0.0        0.0   \n",
       "min    1.000000e-03   3.0   3.0   8.0         2.0     6.0        2.0   \n",
       "25%    1.000000e-03   3.0   3.0   8.0         2.0     6.0        2.0   \n",
       "50%    1.000000e-03   3.0   3.0   8.0         2.0     6.0        2.0   \n",
       "75%    1.000000e-03   3.0   3.0   8.0         2.0     6.0        2.0   \n",
       "max    1.000000e-03   3.0   3.0   8.0         2.0     6.0        2.0   \n",
       "\n",
       "       train_batch_size  test_accuracy   total_su  total_su_fwd  total_su_bwd  \\\n",
       "count         12.000000      12.000000  12.000000     12.000000     12.000000   \n",
       "mean         128.000000       0.974883   2.329637      1.217308      4.860839   \n",
       "std           94.534265       0.024987   0.332491      0.016858      2.440573   \n",
       "min           64.000000       0.906500   1.774110      1.179107      2.287440   \n",
       "25%           64.000000       0.978925   2.114851      1.224516      3.322865   \n",
       "50%           64.000000       0.984550   2.304161      1.224516      4.243915   \n",
       "75%          256.000000       0.988175   2.474343      1.224516      5.075883   \n",
       "max          256.000000       0.990000   2.887780      1.224516     10.484353   \n",
       "\n",
       "       current_sparsity  current_relative_overhead  \n",
       "count         12.000000                  12.000000  \n",
       "mean           0.976017                   0.065514  \n",
       "std            0.023462                   0.041812  \n",
       "min            0.918026                   0.006305  \n",
       "25%            0.985947                   0.026392  \n",
       "50%            0.985947                   0.076212  \n",
       "75%            0.985947                   0.092646  \n",
       "max            0.985947                   0.122770  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: re_pruning, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 4.69, INF. SU: 4.05, SP.: 0.14\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>prune_epochs</th>\n",
       "      <th>metric_q_l</th>\n",
       "      <th>metric_q_c</th>\n",
       "      <th>scale_l</th>\n",
       "      <th>scale_c</th>\n",
       "      <th>sample_l</th>\n",
       "      <th>sample_c</th>\n",
       "      <th>softness_l</th>\n",
       "      <th>softness_c</th>\n",
       "      <th>...</th>\n",
       "      <th>magnitude_t_l</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.18500</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>8.000200e-05</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.973520</td>\n",
       "      <td>13.104644</td>\n",
       "      <td>8.218006</td>\n",
       "      <td>19.987263</td>\n",
       "      <td>0.582957</td>\n",
       "      <td>0.026784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843274</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.08756</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.098793</td>\n",
       "      <td>379.473319</td>\n",
       "      <td>379.473319</td>\n",
       "      <td>0.379473</td>\n",
       "      <td>0.379473</td>\n",
       "      <td>...</td>\n",
       "      <td>2.285699e-19</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.215949e-05</td>\n",
       "      <td>101.192885</td>\n",
       "      <td>0.023407</td>\n",
       "      <td>13.221078</td>\n",
       "      <td>7.166728</td>\n",
       "      <td>24.444213</td>\n",
       "      <td>0.419718</td>\n",
       "      <td>0.029152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>2.209322</td>\n",
       "      <td>1.319949</td>\n",
       "      <td>3.176753</td>\n",
       "      <td>0.087220</td>\n",
       "      <td>0.002751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>3.308599</td>\n",
       "      <td>2.982198</td>\n",
       "      <td>3.553956</td>\n",
       "      <td>0.160415</td>\n",
       "      <td>0.011368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>5.119611</td>\n",
       "      <td>3.963887</td>\n",
       "      <td>6.014473</td>\n",
       "      <td>0.641943</td>\n",
       "      <td>0.015797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.986525</td>\n",
       "      <td>22.265483</td>\n",
       "      <td>14.229037</td>\n",
       "      <td>31.028729</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>0.022041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>39.953028</td>\n",
       "      <td>20.099640</td>\n",
       "      <td>78.938928</td>\n",
       "      <td>0.994771</td>\n",
       "      <td>0.091882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr  prune_epochs  metric_q_l  metric_q_c    scale_l    scale_c  \\\n",
       "count  10.0     10.000000   10.000000    10.00000  10.000000  10.000000   \n",
       "mean    0.1      0.400000    0.035200     0.18500   0.170000   0.076000   \n",
       "std     0.0      0.843274    0.020714     0.08756   0.075277   0.098793   \n",
       "min     0.1      0.000000    0.001000     0.05000   0.100000   0.010000   \n",
       "25%     0.1      0.000000    0.025000     0.12500   0.100000   0.010000   \n",
       "50%     0.1      0.000000    0.050000     0.25000   0.150000   0.010000   \n",
       "75%     0.1      0.000000    0.050000     0.25000   0.250000   0.100000   \n",
       "max     0.1      2.000000    0.050000     0.25000   0.250000   0.250000   \n",
       "\n",
       "          sample_l     sample_c  softness_l  softness_c  ...  magnitude_t_l  \\\n",
       "count    10.000000    10.000000   10.000000   10.000000  ...   1.000000e+01   \n",
       "mean    820.000000   820.000000    0.180000    0.180000  ...   1.000000e-03   \n",
       "std     379.473319   379.473319    0.379473    0.379473  ...   2.285699e-19   \n",
       "min     100.000000   100.000000    0.000000    0.000000  ...   1.000000e-03   \n",
       "25%    1000.000000  1000.000000    0.000000    0.000000  ...   1.000000e-03   \n",
       "50%    1000.000000  1000.000000    0.000000    0.000000  ...   1.000000e-03   \n",
       "75%    1000.000000  1000.000000    0.000000    0.000000  ...   1.000000e-03   \n",
       "max    1000.000000  1000.000000    0.900000    0.900000  ...   1.000000e-03   \n",
       "\n",
       "            l1            l2  train_batch_size  test_accuracy   total_su  \\\n",
       "count  10.0000  1.000000e+01         10.000000      10.000000  10.000000   \n",
       "mean    0.0001  8.000200e-05        160.000000       0.973520  13.104644   \n",
       "std     0.0000  4.215949e-05        101.192885       0.023407  13.221078   \n",
       "min     0.0001  1.000000e-08         64.000000       0.914500   2.209322   \n",
       "25%     0.0001  1.000000e-04         64.000000       0.971000   3.308599   \n",
       "50%     0.0001  1.000000e-04        160.000000       0.984500   5.119611   \n",
       "75%     0.0001  1.000000e-04        256.000000       0.986525  22.265483   \n",
       "max     0.0001  1.000000e-04        256.000000       0.990500  39.953028   \n",
       "\n",
       "       total_su_fwd  total_su_bwd  current_sparsity  current_relative_overhead  \n",
       "count     10.000000     10.000000         10.000000                  10.000000  \n",
       "mean       8.218006     19.987263          0.582957                   0.026784  \n",
       "std        7.166728     24.444213          0.419718                   0.029152  \n",
       "min        1.319949      3.176753          0.087220                   0.002751  \n",
       "25%        2.982198      3.553956          0.160415                   0.011368  \n",
       "50%        3.963887      6.014473          0.641943                   0.015797  \n",
       "75%       14.229037     31.028729          0.992416                   0.022041  \n",
       "max       20.099640     78.938928          0.994771                   0.091882  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: re_pruning_ac, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.98, TRAIN SU: 31.33, INF. SU: 14.29, SP.: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>prune_epochs</th>\n",
       "      <th>metric_q_l</th>\n",
       "      <th>metric_q_c</th>\n",
       "      <th>scale_l</th>\n",
       "      <th>scale_c</th>\n",
       "      <th>sample_l</th>\n",
       "      <th>sample_c</th>\n",
       "      <th>softness_l</th>\n",
       "      <th>softness_c</th>\n",
       "      <th>...</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>ac</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042308</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.037692</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>152.615385</td>\n",
       "      <td>0.957992</td>\n",
       "      <td>30.214258</td>\n",
       "      <td>13.496152</td>\n",
       "      <td>92.753558</td>\n",
       "      <td>0.992089</td>\n",
       "      <td>0.042538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.444446e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.072058</td>\n",
       "      <td>0.043235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410592e-20</td>\n",
       "      <td>1.410592e-20</td>\n",
       "      <td>1.037749</td>\n",
       "      <td>99.623908</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>17.771963</td>\n",
       "      <td>6.236558</td>\n",
       "      <td>92.893506</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.038859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.933400</td>\n",
       "      <td>9.585555</td>\n",
       "      <td>5.853370</td>\n",
       "      <td>14.071709</td>\n",
       "      <td>0.984123</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.938700</td>\n",
       "      <td>18.324637</td>\n",
       "      <td>9.437538</td>\n",
       "      <td>34.629528</td>\n",
       "      <td>0.991503</td>\n",
       "      <td>0.011997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.954100</td>\n",
       "      <td>23.257225</td>\n",
       "      <td>11.252508</td>\n",
       "      <td>50.453300</td>\n",
       "      <td>0.993326</td>\n",
       "      <td>0.027580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.979300</td>\n",
       "      <td>31.329714</td>\n",
       "      <td>14.628076</td>\n",
       "      <td>85.579965</td>\n",
       "      <td>0.994012</td>\n",
       "      <td>0.064893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>69.198344</td>\n",
       "      <td>27.078503</td>\n",
       "      <td>311.333727</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.111399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lr  prune_epochs  metric_q_l  metric_q_c    scale_l  \\\n",
       "count  1.300000e+01          13.0   13.000000   13.000000  13.000000   \n",
       "mean   1.000000e-01           0.0    0.042308    0.211538   0.146154   \n",
       "std    1.444446e-17           0.0    0.012010    0.060048   0.072058   \n",
       "min    1.000000e-01           0.0    0.025000    0.125000   0.100000   \n",
       "25%    1.000000e-01           0.0    0.025000    0.125000   0.100000   \n",
       "50%    1.000000e-01           0.0    0.050000    0.250000   0.100000   \n",
       "75%    1.000000e-01           0.0    0.050000    0.250000   0.250000   \n",
       "max    1.000000e-01           0.0    0.050000    0.250000   0.250000   \n",
       "\n",
       "         scale_c  sample_l  sample_c  softness_l  softness_c  ...  \\\n",
       "count  13.000000      13.0      13.0        13.0        13.0  ...   \n",
       "mean    0.037692    1000.0    1000.0         0.0         0.0  ...   \n",
       "std     0.043235       0.0       0.0         0.0         0.0  ...   \n",
       "min     0.010000    1000.0    1000.0         0.0         0.0  ...   \n",
       "25%     0.010000    1000.0    1000.0         0.0         0.0  ...   \n",
       "50%     0.010000    1000.0    1000.0         0.0         0.0  ...   \n",
       "75%     0.100000    1000.0    1000.0         0.0         0.0  ...   \n",
       "max     0.100000    1000.0    1000.0         0.0         0.0  ...   \n",
       "\n",
       "                 l1            l2         ac  train_batch_size  test_accuracy  \\\n",
       "count  1.300000e+01  1.300000e+01  13.000000         13.000000      13.000000   \n",
       "mean   1.000000e-04  1.000000e-04   2.923077        152.615385       0.957992   \n",
       "std    1.410592e-20  1.410592e-20   1.037749         99.623908       0.019678   \n",
       "min    1.000000e-04  1.000000e-04   2.000000         64.000000       0.933400   \n",
       "25%    1.000000e-04  1.000000e-04   2.000000         64.000000       0.938700   \n",
       "50%    1.000000e-04  1.000000e-04   2.000000         64.000000       0.954100   \n",
       "75%    1.000000e-04  1.000000e-04   4.000000        256.000000       0.979300   \n",
       "max    1.000000e-04  1.000000e-04   4.000000        256.000000       0.984500   \n",
       "\n",
       "        total_su  total_su_fwd  total_su_bwd  current_sparsity  \\\n",
       "count  13.000000     13.000000     13.000000         13.000000   \n",
       "mean   30.214258     13.496152     92.753558          0.992089   \n",
       "std    17.771963      6.236558     92.893506          0.003215   \n",
       "min     9.585555      5.853370     14.071709          0.984123   \n",
       "25%    18.324637      9.437538     34.629528          0.991503   \n",
       "50%    23.257225     11.252508     50.453300          0.993326   \n",
       "75%    31.329714     14.628076     85.579965          0.994012   \n",
       "max    69.198344     27.078503    311.333727          0.994987   \n",
       "\n",
       "       current_relative_overhead  \n",
       "count                  13.000000  \n",
       "mean                    0.042538  \n",
       "std                     0.038859  \n",
       "min                     0.007092  \n",
       "25%                     0.011997  \n",
       "50%                     0.027580  \n",
       "75%                     0.064893  \n",
       "max                     0.111399  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: re_pruning_admm_intra, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 13.7, INF. SU: 12.02, SP.: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>prune_epochs</th>\n",
       "      <th>metric_q_l</th>\n",
       "      <th>metric_q_c</th>\n",
       "      <th>scale_l</th>\n",
       "      <th>scale_c</th>\n",
       "      <th>sample_l</th>\n",
       "      <th>sample_c</th>\n",
       "      <th>softness_l</th>\n",
       "      <th>softness_c</th>\n",
       "      <th>...</th>\n",
       "      <th>pre_epochs</th>\n",
       "      <th>epochs</th>\n",
       "      <th>re_epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36.000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.00000</td>\n",
       "      <td>0.939108</td>\n",
       "      <td>8.799212</td>\n",
       "      <td>6.523557</td>\n",
       "      <td>11.244347</td>\n",
       "      <td>0.986744</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.059761</td>\n",
       "      <td>0.071714</td>\n",
       "      <td>0.043028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.36177</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>9.651804</td>\n",
       "      <td>8.931164</td>\n",
       "      <td>10.594989</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>4.658405</td>\n",
       "      <td>3.286416</td>\n",
       "      <td>5.887296</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>0.032019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>0.987475</td>\n",
       "      <td>4.980152</td>\n",
       "      <td>3.601271</td>\n",
       "      <td>6.081007</td>\n",
       "      <td>0.985949</td>\n",
       "      <td>0.032022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.00000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>5.540613</td>\n",
       "      <td>4.078805</td>\n",
       "      <td>7.208564</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.080065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.00000</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>8.648460</td>\n",
       "      <td>5.556454</td>\n",
       "      <td>10.991124</td>\n",
       "      <td>0.985972</td>\n",
       "      <td>0.128273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.00000</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>49.075764</td>\n",
       "      <td>44.193139</td>\n",
       "      <td>51.945322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lr  prune_epochs  metric_q_l  metric_q_c    scale_l    scale_c  \\\n",
       "count  36.000          36.0   36.000000   36.000000  36.000000  36.000000   \n",
       "mean    0.001           0.0    0.041667    0.208333   0.150000   0.040000   \n",
       "std     0.000           0.0    0.011952    0.059761   0.071714   0.043028   \n",
       "min     0.001           0.0    0.025000    0.125000   0.100000   0.010000   \n",
       "25%     0.001           0.0    0.025000    0.125000   0.100000   0.010000   \n",
       "50%     0.001           0.0    0.050000    0.250000   0.100000   0.010000   \n",
       "75%     0.001           0.0    0.050000    0.250000   0.250000   0.100000   \n",
       "max     0.001           0.0    0.050000    0.250000   0.250000   0.100000   \n",
       "\n",
       "       sample_l  sample_c  softness_l  softness_c  ...  pre_epochs  epochs  \\\n",
       "count      36.0      36.0        36.0        36.0  ...        36.0    36.0   \n",
       "mean     1000.0    1000.0         0.0         0.0  ...         1.0     1.0   \n",
       "std         0.0       0.0         0.0         0.0  ...         0.0     0.0   \n",
       "min      1000.0    1000.0         0.0         0.0  ...         1.0     1.0   \n",
       "25%      1000.0    1000.0         0.0         0.0  ...         1.0     1.0   \n",
       "50%      1000.0    1000.0         0.0         0.0  ...         1.0     1.0   \n",
       "75%      1000.0    1000.0         0.0         0.0  ...         1.0     1.0   \n",
       "max      1000.0    1000.0         0.0         0.0  ...         1.0     1.0   \n",
       "\n",
       "       re_epochs  train_batch_size  test_accuracy   total_su  total_su_fwd  \\\n",
       "count       36.0          36.00000      36.000000  36.000000     36.000000   \n",
       "mean         1.0         160.00000       0.939108   8.799212      6.523557   \n",
       "std          0.0          97.36177       0.206897   9.651804      8.931164   \n",
       "min          1.0          64.00000       0.098000   4.658405      3.286416   \n",
       "25%          1.0          64.00000       0.987475   4.980152      3.601271   \n",
       "50%          1.0         160.00000       0.989000   5.540613      4.078805   \n",
       "75%          1.0         256.00000       0.989400   8.648460      5.556454   \n",
       "max          1.0         256.00000       0.990400  49.075764     44.193139   \n",
       "\n",
       "       total_su_bwd  current_sparsity  current_relative_overhead  \n",
       "count     36.000000         36.000000                  36.000000  \n",
       "mean      11.244347          0.986744                        inf  \n",
       "std       10.594989          0.003261                        NaN  \n",
       "min        5.887296          0.985947                   0.032019  \n",
       "25%        6.081007          0.985949                   0.032022  \n",
       "50%        7.208564          0.985954                   0.080065  \n",
       "75%       10.991124          0.985972                   0.128273  \n",
       "max       51.945322          1.000000                        inf  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP.: re_pruning_admm_retrain, MODEL: lenet, DATA: mnist\n",
      "ACC.: 0.99, TRAIN SU: 8.18, INF. SU: 12.14, SP.: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>prune_epochs</th>\n",
       "      <th>metric_q_l</th>\n",
       "      <th>metric_q_c</th>\n",
       "      <th>scale_l</th>\n",
       "      <th>scale_c</th>\n",
       "      <th>sample_l</th>\n",
       "      <th>sample_c</th>\n",
       "      <th>softness_l</th>\n",
       "      <th>softness_c</th>\n",
       "      <th>...</th>\n",
       "      <th>pre_epochs</th>\n",
       "      <th>epochs</th>\n",
       "      <th>re_epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_su</th>\n",
       "      <th>total_su_fwd</th>\n",
       "      <th>total_su_bwd</th>\n",
       "      <th>current_sparsity</th>\n",
       "      <th>current_relative_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48.000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.909877</td>\n",
       "      <td>7.162793</td>\n",
       "      <td>6.055424</td>\n",
       "      <td>7.963043</td>\n",
       "      <td>0.987244</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.063161</td>\n",
       "      <td>0.065639</td>\n",
       "      <td>0.039384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505291</td>\n",
       "      <td>2.526456</td>\n",
       "      <td>0.505291</td>\n",
       "      <td>93.935243</td>\n",
       "      <td>0.247452</td>\n",
       "      <td>4.132728</td>\n",
       "      <td>3.469440</td>\n",
       "      <td>4.731617</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>4.601207</td>\n",
       "      <td>3.972100</td>\n",
       "      <td>4.996917</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.032032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.977200</td>\n",
       "      <td>5.289321</td>\n",
       "      <td>4.690808</td>\n",
       "      <td>5.553624</td>\n",
       "      <td>0.985993</td>\n",
       "      <td>0.032082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.983250</td>\n",
       "      <td>5.559343</td>\n",
       "      <td>4.937125</td>\n",
       "      <td>5.817858</td>\n",
       "      <td>0.986058</td>\n",
       "      <td>0.032255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.989300</td>\n",
       "      <td>6.560154</td>\n",
       "      <td>5.160470</td>\n",
       "      <td>7.804492</td>\n",
       "      <td>0.986145</td>\n",
       "      <td>0.129386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.990900</td>\n",
       "      <td>22.117961</td>\n",
       "      <td>18.511103</td>\n",
       "      <td>24.505378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lr  prune_epochs  metric_q_l  metric_q_c    scale_l    scale_c  \\\n",
       "count  48.000          48.0   48.000000   48.000000  48.000000  48.000000   \n",
       "mean    0.001           0.0    0.037500    0.187500   0.137500   0.032500   \n",
       "std     0.000           0.0    0.012632    0.063161   0.065639   0.039384   \n",
       "min     0.001           0.0    0.025000    0.125000   0.100000   0.010000   \n",
       "25%     0.001           0.0    0.025000    0.125000   0.100000   0.010000   \n",
       "50%     0.001           0.0    0.037500    0.187500   0.100000   0.010000   \n",
       "75%     0.001           0.0    0.050000    0.250000   0.137500   0.032500   \n",
       "max     0.001           0.0    0.050000    0.250000   0.250000   0.100000   \n",
       "\n",
       "       sample_l  sample_c  softness_l  softness_c  ...  pre_epochs     epochs  \\\n",
       "count      48.0      48.0        48.0        48.0  ...   48.000000  48.000000   \n",
       "mean     1000.0    1000.0         0.0         0.0  ...    1.500000   3.500000   \n",
       "std         0.0       0.0         0.0         0.0  ...    0.505291   2.526456   \n",
       "min      1000.0    1000.0         0.0         0.0  ...    1.000000   1.000000   \n",
       "25%      1000.0    1000.0         0.0         0.0  ...    1.000000   1.000000   \n",
       "50%      1000.0    1000.0         0.0         0.0  ...    1.500000   3.500000   \n",
       "75%      1000.0    1000.0         0.0         0.0  ...    2.000000   6.000000   \n",
       "max      1000.0    1000.0         0.0         0.0  ...    2.000000   6.000000   \n",
       "\n",
       "       re_epochs  train_batch_size  test_accuracy   total_su  total_su_fwd  \\\n",
       "count  48.000000         48.000000      48.000000  48.000000     48.000000   \n",
       "mean    1.500000        184.000000       0.909877   7.162793      6.055424   \n",
       "std     0.505291         93.935243       0.247452   4.132728      3.469440   \n",
       "min     1.000000         64.000000       0.098000   4.601207      3.972100   \n",
       "25%     1.000000         64.000000       0.977200   5.289321      4.690808   \n",
       "50%     1.500000        256.000000       0.983250   5.559343      4.937125   \n",
       "75%     2.000000        256.000000       0.989300   6.560154      5.160470   \n",
       "max     2.000000        256.000000       0.990900  22.117961     18.511103   \n",
       "\n",
       "       total_su_bwd  current_sparsity  current_relative_overhead  \n",
       "count     48.000000         48.000000                  48.000000  \n",
       "mean       7.963043          0.987244                        inf  \n",
       "std        4.731617          0.003891                        NaN  \n",
       "min        4.996917          0.985954                   0.032032  \n",
       "25%        5.553624          0.985993                   0.032082  \n",
       "50%        5.817858          0.986058                   0.032255  \n",
       "75%        7.804492          0.986145                   0.129386  \n",
       "max       24.505378          1.000000                        inf  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'pre_epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6e9da08e378b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;34m'sample_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softness_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softness_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'magnitude_t_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'magnitude_t_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ac'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'repeat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0;34m'train_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'test_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_su'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_su_fwd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_su_bwd'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'pre_epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m're_epochs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m       'current_sparsity', 'current_relative_overhead'], plt_corr)\n\u001b[0m\u001b[1;32m     86\u001b[0m cross_eval(best_results, datasets, models, 're_pruning_ac_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n\u001b[1;32m     87\u001b[0m       \u001b[0;34m'sample_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softness_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softness_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'magnitude_t_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'magnitude_t_l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ac'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pre_epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m're_epochs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f6e5fa3a7808>\u001b[0m in \u001b[0;36mcross_eval\u001b[0;34m(best_results, datasets, models, name, specs_to_print, results_to_print, plt_corr)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;31m#outstring += '\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_to_print\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOGDATA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                             \u001b[0moutstring\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOGDATA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pre_epochs'"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    'cifar10', \n",
    "    'cifar100', \n",
    "    'mnist',\n",
    "    'imagenet_tiny',\n",
    "    'imagenet_full',\n",
    "]\n",
    "models = [\n",
    "    #'resnet18', \n",
    "    #'resnet20',\n",
    "    #'resnet32',\n",
    "    #'resnet34',\n",
    "    #'resnet50',\n",
    "    #'alexnet_s', \n",
    "    #'alexnet',\n",
    "    'lenet', \n",
    "    #'mobilenet_v2', \n",
    "    #'mobilenet_v3_s', \n",
    "    #'vgg8',\n",
    "    #'vgg11', \n",
    "    #'vgg13', \n",
    "    #'vgg16'\n",
    "         ]\n",
    "best_results = {}\n",
    "plt_corr = True\n",
    "sns.set(rc={'figure.figsize':(1.33*11.7,1.33*8.27)})\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 'baseline', ['lr', 'epochs', 'train_batch_size'], ['test_accuracy'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 'admm_intra', \n",
    "     ['lr', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'admm_retrain', \n",
    "     ['lr', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k', ['lr', 'k', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc', ['lr', 'k', 'se', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac_dk', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac_dk_admm_intra', \n",
    "     ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 'gd_top_k_mc_ac_dk_admm_retrain',  \n",
    "     ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "     ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "      'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_ac', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', 'ac', \n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'repeat', 'pre_epochs', 'epochs', 're_epochs',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'pre_epochs', 'epochs', 're_epochs',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_ac_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', 'repeat',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd',  'pre_epochs', 'epochs', 're_epochs',\n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "cross_eval(best_results, datasets, models, 're_pruning_ac_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "      'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', 'pre_epochs', 'epochs', 're_epochs',\n",
    "      'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "      'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning_gd_top_k_mc_ac_dk_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "      'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "      'magnitude_t_l', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "      'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "cross_eval(best_results, datasets, models, 're_pruning_gd_top_k_mc_ac_dk_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "      'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "      'magnitude_t_l', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "      'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], plt_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_n, search_m, search_d = 're_pruning_gd_top_k_mc_ac_dk_admm_intra', 'resnet50', 'cifar10'\n",
    "for name in best_results:\n",
    "    if name == search_n:\n",
    "        for model in best_results[name]['cfg']:\n",
    "            if search_m == model:\n",
    "                for data in best_results[name]['cfg'][model]:\n",
    "                    if search_d == data:\n",
    "                        if 'METADATA' in best_results[name]['cfg'][model][data]:\n",
    "                            print(best_results[name]['cfg'][model][data]['METADATA'])\n",
    "        #print(best_results[name]['cfg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-niagara",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_logdict = {}\n",
    "for log in logs:\n",
    "    for key in log['LOGDATA']:\n",
    "        new_key = log['METADATA']['EXPERIMENT']['dataset'] + '+'\n",
    "        new_key += log['METADATA']['EXPERIMENT']['name'] + '+'\n",
    "        new_key += log['METADATA']['EXPERIMENT']['model']\n",
    "        if log['LOGDATA']['test_accuracy'][-1] <= 0.1:\n",
    "                continue\n",
    "        if new_key not in new_logdict:\n",
    "            new_logdict[new_key] = {}\n",
    "        if key not in new_logdict[new_key]:\n",
    "            new_logdict[new_key][key] = []\n",
    "            \n",
    "        if 'overhead' in key:\n",
    "            #print(sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]), flush=True)\n",
    "            if ('_mc' in log['METADATA']['EXPERIMENT']['name'] and\n",
    "                'gd' in log['METADATA']['EXPERIMENT']['name'] and not\n",
    "                'admm' in log['METADATA']['EXPERIMENT']['name']):\n",
    "                \n",
    "                    idx = int((len(log['LOGDATA'][key])*\n",
    "                           float(log['METADATA']['SPECIFICATION']['se'])/\n",
    "                           float(log['METADATA']['SPECIFICATION']['epochs'])))+1\n",
    "                    new_logdict[new_key][key].append(sum(log['LOGDATA'][key][:idx])/len(log['LOGDATA'][key]))\n",
    "                    #print(log['METADATA']['EXPERIMENT']['name'], \n",
    "                    #      sum(log['LOGDATA'][key][:idx])/len(log['LOGDATA'][key]),\n",
    "                    #      sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]))\n",
    "            else:\n",
    "                new_logdict[new_key][key].append(sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]))\n",
    "        elif 'gradient' in key:\n",
    "            new_logdict[new_key][key].append(sum(log['LOGDATA'][key])/len(log['LOGDATA'][key]))\n",
    "        else:\n",
    "            new_logdict[new_key][key].append(log['LOGDATA'][key][-1])\n",
    "        \n",
    "n = 5\n",
    "prec = 2\n",
    "x = []\n",
    "y = []\n",
    "area = []\n",
    "names = []\n",
    "colors = []\n",
    "for key in new_logdict:\n",
    "    if (not 'baseline' in key and '+lenet' in key and not 'cifar100' in key):\n",
    "       #and 're_pruning_gd_top_k_mc_ac_dk_admm_intra' in key):#('+resnet' in key or '+alexnet' in key or '+lenet' in key):\n",
    "        print(key)\n",
    "        idx = sorted(range(len(new_logdict[key]['test_accuracy'])), \n",
    "                     key=lambda i: new_logdict[key]['test_accuracy'][i])[-n:]\n",
    "        #idx = idx[:10]\n",
    "        idx.reverse()\n",
    "        print('Acc, C/F, P, FLOPs(I), FLOPs(T), G')\n",
    "        \n",
    "        y.append(round((1-1/new_logdict[key]['total_su'][0])/\n",
    "                 (1-new_logdict[key]['test_accuracy'][0]),prec))\n",
    "        \n",
    "        x.append(round(1-1/new_logdict[key]['total_su'][0],prec))\n",
    "        \n",
    "        area.append(round(new_logdict[key]['test_accuracy'][0]/\n",
    "                 (1-new_logdict[key]['current_sparsity'][0])*100+1,prec))\n",
    "        \n",
    "        colors.append(int(round(new_logdict[key]['current_relative_overhead'][0]/\n",
    "                                max(new_logdict[key]['current_relative_overhead'])*100,prec)))\n",
    "        \n",
    "        name_candidate = key.split('+')[1]\n",
    "        name_candidate = name_candidate.replace('re_pruning', 'REP')\n",
    "        name_candidate = name_candidate.replace('gd_top_k_mc', 'GDTopKMC')\n",
    "        name_candidate = name_candidate.replace('gd_top_k', 'GDTopK')\n",
    "        name_candidate = name_candidate.replace('ac', 'AC')\n",
    "        name_candidate = name_candidate.replace('dk', 'DK')\n",
    "        name_candidate = name_candidate.replace('admm_retrain', 'ADMMR')\n",
    "        name_candidate = name_candidate.replace('admm_intra', 'ADMMI')\n",
    "        name_candidate = name_candidate.replace('_', '+')\n",
    "        names.append(name_candidate)\n",
    "        for i in idx:\n",
    "            #print(new_logdict[key].keys()) #current_channel_sparsity', 'current_linear_sparsity #current_relative_overhead'\n",
    "            print(round(new_logdict[key]['test_accuracy'][i],prec), \n",
    "                  round(new_logdict[key]['current_channel_sparsity'][i],prec),\n",
    "                  round(new_logdict[key]['current_sparsity'][i],prec),\n",
    "                  round(1-1/new_logdict[key]['current_su_fwd'][i],prec),\n",
    "                  round(1-1/new_logdict[key]['total_su'][i],prec),\n",
    "                  round(new_logdict[key]['current_gradient_sparsity'][i],prec),\n",
    "                  #round(new_logdict[key]['current_relative_overhead'][i]*1e5, prec),\n",
    "                  #round(1-1/new_logdict[key]['current_su_bwd'][i],prec),\n",
    "                  #round(new_logdict[key]['total_su'][i],prec),\n",
    "                  #round(new_logdict[key]['current_sparsity'][i],prec))+\n",
    "                  )\n",
    "                  #round(new_logdict[key]['current_relative_overhead'][i],prec))\n",
    "        print('\\n')\n",
    "    #for subkey in new_logdict[key]:\n",
    "    #    if not 'features' in subkey and not 'weight' in subkey:\n",
    "            \n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "for i, txt in enumerate(names):\n",
    "    plt.annotate(txt, (x[i], y[i]))\n",
    "plt.ylabel('FLOPs(T) per Delta Acc.')\n",
    "plt.xlabel('FLOPs(T)')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-crystal",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "datasets = [\n",
    "    'cifar10', \n",
    "    'cifar100', \n",
    "    'mnist',\n",
    "    'imagenet'\n",
    "]\n",
    "models = [\n",
    "    'resnet18', \n",
    "    'alexnet_s', \n",
    "    'lenet', \n",
    "    'mobilenet_v2', \n",
    "    'mobilenet_v3', \n",
    "    'vgg8',\n",
    "    'vgg11', \n",
    "    'vgg13', \n",
    "    'vgg16'\n",
    "         ]\n",
    "plt_corr = False\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'baseline', ['lr', 'epochs', 'train_batch_size'], ['test_accuracy'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'admm_intra', \n",
    "             ['lr', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'admm_retrain', \n",
    "             ['lr', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 'gd_top_k', ['lr', 'k', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc', ['lr', 'k', 'se', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk', ['lr', 'k', 'se', 'ac', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk_admm_intra', \n",
    "             ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'repeat', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 'gd_top_k_mc_ac_dk_admm_retrain',  \n",
    "             ['lr', 'k', 'se', 'ac', 'pre_epochs', 'epochs', 're_epochs', 'train_batch_size'], \n",
    "             ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', 'current_sparsity', \n",
    "              'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'l1', 'l2', 'ac', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'repeat',\n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', 'repeat',\n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "        single_eval(dataset, model, 're_pruning_ac_admm_retrain', ['lr', 'prune_epochs', 'metric_q_l', 'metric_q_c', 'scale_l', 'scale_c',\n",
    "              'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', 'magnitude_t_l', 'ac', \n",
    "              'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', 'total_su_bwd', \n",
    "              'current_sparsity', 'current_relative_overhead'], plt_corr)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        single_eval(dataset, model, 're_pruning_gd_top_k_mc_ac_dk_admm_intra', ['lr', 'prune_epochs', 'metric_q_l', \n",
    "              'metric_q_c', 'scale_l', 'scale_c', 'sample_l', 'sample_c', 'softness_l', 'softness_c', 'magnitude_t_c', \n",
    "              'magnitude_t_l', 'l1', 'l2', 'ac', 'train_batch_size'], ['test_accuracy', 'total_su', 'total_su_fwd', \n",
    "              'total_su_bwd', 'current_sparsity', 'current_relative_overhead'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-cookie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
